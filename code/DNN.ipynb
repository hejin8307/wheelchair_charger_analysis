{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "uzVrpwJkK1Tf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "import keras\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "# import seaborn as sns\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    "from sklearn.metrics import mean_squared_error, explained_variance_score\n",
    "from keras.callbacks import EarlyStopping\n",
    "from matplotlib import font_manager, rc\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import keras\n",
    "import sklearn\n",
    "\n",
    "# 다변량\n",
    "def split_mult_data(data, timestep, lag):\n",
    "    x, y = [], []\n",
    "    for i in range(len(data)):\n",
    "        end_ix = i + timestep\n",
    "        out_end_ix = end_ix + lag\n",
    "        if out_end_ix > len(data):\n",
    "            break;\n",
    "        seq_x, seq_y = data[i:end_ix, :], data[end_ix:out_end_ix, 0]\n",
    "        x.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(x), array(y)\n",
    "\n",
    "# 단일\n",
    "def split_data(data, timestep):\n",
    "    x, y = [], []\n",
    "    for i in range(len(data)):\n",
    "        end_ix = i + timestep\n",
    "        if end_ix > len(data)-1:\n",
    "            break\n",
    "        seq_x, seq_y = data[i:end_ix], data[end_ix]\n",
    "        x.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(x), array(y)\n",
    "\n",
    "# 데이터 분할 함수 : 6.2.2 (나눌때 사용)\n",
    "def split(data_x, data_y):\n",
    "    train_size = int(len(data_x)*0.6)\n",
    "    val_size = int(len(data_x)*0.8)\n",
    "    \n",
    "    data_train_x = data_x[:train_size]\n",
    "    data_val_x = data_x[train_size:val_size]\n",
    "    data_test_x = data_x[val_size:]\n",
    "    \n",
    "    data_train_y = data_y[:train_size]\n",
    "    data_val_y = data_y[train_size:val_size]\n",
    "    data_test_y = data_y[val_size:] \n",
    "    \n",
    "    return data_train_x, data_val_x, data_test_x, data_train_y, data_val_y, data_test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9JHZi56eewSr",
    "tags": []
   },
   "source": [
    "# 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "id": "9sorSai6ekMG",
    "outputId": "c30f7e09-ae3d-4d61-d7f6-ad70bc3f9e81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE 적용 후 학습용 피처/레이블 데이터 세트:  (998, 8) (998,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>culture</th>\n",
       "      <th>build1</th>\n",
       "      <th>build2</th>\n",
       "      <th>build3</th>\n",
       "      <th>build4</th>\n",
       "      <th>build5</th>\n",
       "      <th>build6</th>\n",
       "      <th>build7</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>0.195497</td>\n",
       "      <td>0.477161</td>\n",
       "      <td>0.050592</td>\n",
       "      <td>0.692142</td>\n",
       "      <td>0.153196</td>\n",
       "      <td>0.341791</td>\n",
       "      <td>0.781347</td>\n",
       "      <td>0.090310</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>0.100968</td>\n",
       "      <td>0.497016</td>\n",
       "      <td>0.063101</td>\n",
       "      <td>0.541688</td>\n",
       "      <td>0.176717</td>\n",
       "      <td>0.217213</td>\n",
       "      <td>0.726333</td>\n",
       "      <td>0.083032</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>0.912409</td>\n",
       "      <td>0.492984</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.981248</td>\n",
       "      <td>0.300592</td>\n",
       "      <td>0.255252</td>\n",
       "      <td>0.551081</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>0.087591</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.149425</td>\n",
       "      <td>0.157480</td>\n",
       "      <td>0.050787</td>\n",
       "      <td>0.036101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>0.140953</td>\n",
       "      <td>0.466094</td>\n",
       "      <td>0.069952</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.236625</td>\n",
       "      <td>0.161825</td>\n",
       "      <td>0.667478</td>\n",
       "      <td>0.078551</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>0.021898</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.152381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114943</td>\n",
       "      <td>0.039370</td>\n",
       "      <td>0.125894</td>\n",
       "      <td>0.061372</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>0.370823</td>\n",
       "      <td>0.432237</td>\n",
       "      <td>0.035037</td>\n",
       "      <td>0.900781</td>\n",
       "      <td>0.151271</td>\n",
       "      <td>0.494509</td>\n",
       "      <td>0.993684</td>\n",
       "      <td>0.134021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.153285</td>\n",
       "      <td>0.327778</td>\n",
       "      <td>0.152381</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.091954</td>\n",
       "      <td>0.259843</td>\n",
       "      <td>0.371602</td>\n",
       "      <td>0.075812</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>0.716249</td>\n",
       "      <td>0.577903</td>\n",
       "      <td>0.080137</td>\n",
       "      <td>0.021688</td>\n",
       "      <td>0.934970</td>\n",
       "      <td>0.322444</td>\n",
       "      <td>0.251729</td>\n",
       "      <td>0.400836</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>0.043796</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.076190</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.057471</td>\n",
       "      <td>0.236220</td>\n",
       "      <td>0.262876</td>\n",
       "      <td>0.101083</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>998 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      culture    build1    build2    build3    build4    build5    build6  \\\n",
       "743  0.195497  0.477161  0.050592  0.692142  0.153196  0.341791  0.781347   \n",
       "583  0.100968  0.497016  0.063101  0.541688  0.176717  0.217213  0.726333   \n",
       "567  0.912409  0.492984  0.066667  0.074074  0.981248  0.300592  0.255252   \n",
       "262  0.087591  0.377778  0.057143  0.222222  0.149425  0.157480  0.050787   \n",
       "853  0.140953  0.466094  0.069952  0.481481  0.236625  0.161825  0.667478   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "381  0.021898  0.644444  0.152381  0.000000  0.114943  0.039370  0.125894   \n",
       "580  0.370823  0.432237  0.035037  0.900781  0.151271  0.494509  0.993684   \n",
       "33   0.153285  0.327778  0.152381  0.407407  0.091954  0.259843  0.371602   \n",
       "686  0.716249  0.577903  0.080137  0.021688  0.934970  0.322444  0.251729   \n",
       "410  0.043796  0.616667  0.076190  0.074074  0.057471  0.236220  0.262876   \n",
       "\n",
       "       build7  label  \n",
       "743  0.090310      1  \n",
       "583  0.083032      1  \n",
       "567  0.551081      1  \n",
       "262  0.036101      0  \n",
       "853  0.078551      1  \n",
       "..        ...    ...  \n",
       "381  0.061372      0  \n",
       "580  0.134021      1  \n",
       "33   0.075812      0  \n",
       "686  0.400836      1  \n",
       "410  0.101083      0  \n",
       "\n",
       "[998 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 군집화 결과 데이터\n",
    "df = pd.read_csv(\"군집화_결과.csv\",  header=0, squeeze=True)\n",
    "X = df.iloc[:, 1:-1]\n",
    "Y = df.iloc[:, -1]\n",
    "\n",
    "smote = SMOTE(random_state=0)\n",
    "X, Y = smote.fit_resample(X.values, Y.values)\n",
    "print('SMOTE 적용 후 학습용 피처/레이블 데이터 세트: ', X.shape, Y.shape)\n",
    "\n",
    "data = pd.DataFrame(X, columns=['culture', 'build1', 'build2', 'build3', 'build4', 'build5', 'build6','build7'])\n",
    "data['label'] = Y\n",
    "\n",
    "df_shuffled=sklearn.utils.shuffle(data,random_state=555)      #학습, 검정, 테스트 셋 나눌때 랜덤하게 안돼서 미리 섞음\n",
    "X = df_shuffled.iloc[:, :-1]                 #섞은 후 다시 X,Y 나눔\n",
    "Y = df_shuffled.iloc[:, -1]\n",
    "\n",
    "df_shuffled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k1mMJ8kTc4dz"
   },
   "source": [
    "# 6:2:2 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "598 200 200 598 200 200 (598, 8) (200, 8) (200, 8)\n"
     ]
    }
   ],
   "source": [
    "search_train_x, search_val_x, search_test_x, search_train_y, search_val_y, search_test_y = split(X, Y)\n",
    "print(len(search_train_x), len(search_val_x), len(search_test_x), len(search_train_y), len(search_val_x), len(search_test_y), search_train_x.shape, search_val_x.shape,  search_test_x.shape)\n",
    "#위에 split 함수 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClearTrainingOutput(tf.keras.callbacks.Callback):\n",
    "    def on_train_end(*args, **kwargs):\n",
    "        IPython.display.clear_output(wait = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "딥러닝 파라미터 값 찾기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 46 Complete [00h 00m 01s]\n",
      "val_accuracy: 0.9950000047683716\n",
      "\n",
      "Best val_accuracy So Far: 1.0\n",
      "Total elapsed time: 00h 00m 31s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "\n",
      "The hyperparameter search is complete. \n",
      "The optimal number of units in the first densely-connected layer is 16, 12 \n",
      "and the best optimizer is adam.\n"
     ]
    }
   ],
   "source": [
    "# !pip install IPython\n",
    "# !pip install -q -U keras-tuner\n",
    "import kerastuner as kt\n",
    "import IPython\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.random.set_seed(555)                                                              #랜덤시드 555설정\n",
    "\n",
    "class ClearTrainingOutput(tf.keras.callbacks.Callback):\n",
    "    def on_train_end(*args, **kwargs):\n",
    "        IPython.display.clear_output(wait = True)                                    # 훈련 단계가 끝날때마다 결과를 지우도록 콜백 \n",
    "\n",
    "def model_builder(hp):\n",
    "    \n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.Input(shape=(search_train_x.shape[1],)))\n",
    "\n",
    "    hp_units1 = hp.Int('units1', min_value = 8 , max_value = 32, step = 8)           # 첫번째 층 노드 수\n",
    "    hp_units2 = hp.Int('units2', min_value = 4, max_value = 16, step = 4)            # 두번째 층 노드 수\n",
    "    model.add(keras.layers.Dense(units = hp_units1, activation = 'relu'))\n",
    "    model.add(layers.Dense(units = hp_units2, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    opt = hp.Choice('dense_activation', values = ['adam', 'rmsprop','nadam'])        # optimizer 설정\n",
    "    \n",
    "    model.compile(optimizer = opt, \n",
    "                  loss='binary_crossentropy', metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective = 'val_accuracy', \n",
    "                     max_epochs = 10,\n",
    "                     factor = 2,\n",
    "                     overwrite=True,\n",
    "                     seed = 0)\n",
    "\n",
    "tuner.search(search_train_x, search_train_y, epochs=10, batch_size = 10,\n",
    "                 callbacks=[ClearTrainingOutput()], validation_data=(search_val_x, search_val_y))\n",
    "\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
    "\n",
    "# 최적의 파라미터 값 출력\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. \n",
    "The optimal number of units in the first densely-connected layer is {best_hps.get('units1')}, {best_hps.get('units2')} \n",
    "and the best optimizer is {best_hps.get('dense_activation')}.\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M2yEK6P-djmy"
   },
   "source": [
    "# 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ptn6U-s2Yz52",
    "outputId": "34a1a00f-61ce-4a56-e036-7448dfad879c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.6024 - accuracy: 0.8227 - val_loss: 0.5188 - val_accuracy: 0.8750\n",
      "Epoch 2/1000\n",
      "60/60 [==============================] - 0s 818us/step - loss: 0.4309 - accuracy: 0.9431 - val_loss: 0.3721 - val_accuracy: 0.9700\n",
      "Epoch 3/1000\n",
      "60/60 [==============================] - 0s 760us/step - loss: 0.2839 - accuracy: 0.9883 - val_loss: 0.2287 - val_accuracy: 0.9950\n",
      "Epoch 4/1000\n",
      "60/60 [==============================] - 0s 830us/step - loss: 0.1587 - accuracy: 0.9933 - val_loss: 0.1272 - val_accuracy: 0.9950\n",
      "Epoch 5/1000\n",
      "60/60 [==============================] - 0s 811us/step - loss: 0.0875 - accuracy: 0.9933 - val_loss: 0.0783 - val_accuracy: 0.9950\n",
      "Epoch 6/1000\n",
      "60/60 [==============================] - 0s 828us/step - loss: 0.0508 - accuracy: 0.9967 - val_loss: 0.0606 - val_accuracy: 0.9800\n",
      "Epoch 7/1000\n",
      "60/60 [==============================] - 0s 811us/step - loss: 0.0355 - accuracy: 0.9950 - val_loss: 0.0364 - val_accuracy: 1.0000\n",
      "Epoch 8/1000\n",
      "60/60 [==============================] - 0s 811us/step - loss: 0.0252 - accuracy: 0.9967 - val_loss: 0.0256 - val_accuracy: 1.0000\n",
      "Epoch 9/1000\n",
      "60/60 [==============================] - 0s 811us/step - loss: 0.0195 - accuracy: 0.9967 - val_loss: 0.0196 - val_accuracy: 1.0000\n",
      "Epoch 10/1000\n",
      "60/60 [==============================] - 0s 828us/step - loss: 0.0159 - accuracy: 0.9967 - val_loss: 0.0180 - val_accuracy: 1.0000\n",
      "Epoch 11/1000\n",
      "60/60 [==============================] - 0s 821us/step - loss: 0.0139 - accuracy: 0.9967 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
      "Epoch 12/1000\n",
      "60/60 [==============================] - 0s 796us/step - loss: 0.0124 - accuracy: 0.9967 - val_loss: 0.0130 - val_accuracy: 1.0000\n",
      "Epoch 13/1000\n",
      "60/60 [==============================] - 0s 825us/step - loss: 0.0102 - accuracy: 0.9967 - val_loss: 0.0142 - val_accuracy: 1.0000\n",
      "Epoch 14/1000\n",
      "60/60 [==============================] - 0s 989us/step - loss: 0.0093 - accuracy: 0.9983 - val_loss: 0.0155 - val_accuracy: 1.0000\n",
      "Epoch 15/1000\n",
      "60/60 [==============================] - 0s 777us/step - loss: 0.0089 - accuracy: 0.9967 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
      "Epoch 16/1000\n",
      "60/60 [==============================] - 0s 777us/step - loss: 0.0079 - accuracy: 0.9983 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 17/1000\n",
      "60/60 [==============================] - 0s 760us/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
      "Epoch 18/1000\n",
      "60/60 [==============================] - 0s 758us/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 19/1000\n",
      "60/60 [==============================] - 0s 801us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 20/1000\n",
      "60/60 [==============================] - 0s 824us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 21/1000\n",
      "60/60 [==============================] - 0s 760us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 22/1000\n",
      "60/60 [==============================] - 0s 811us/step - loss: 0.0046 - accuracy: 0.9983 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 23/1000\n",
      "60/60 [==============================] - 0s 841us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
      "Epoch 24/1000\n",
      "60/60 [==============================] - 0s 824us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 25/1000\n",
      "60/60 [==============================] - 0s 789us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 26/1000\n",
      "60/60 [==============================] - 0s 819us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 27/1000\n",
      "60/60 [==============================] - 0s 845us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 28/1000\n",
      "60/60 [==============================] - 0s 760us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 29/1000\n",
      "60/60 [==============================] - 0s 801us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 30/1000\n",
      "60/60 [==============================] - 0s 809us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 31/1000\n",
      "60/60 [==============================] - 0s 864us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 32/1000\n",
      "60/60 [==============================] - 0s 811us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 33/1000\n",
      "60/60 [==============================] - 0s 845us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 34/1000\n",
      "60/60 [==============================] - 0s 760us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 35/1000\n",
      "60/60 [==============================] - 0s 814us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 9.6940e-04 - val_accuracy: 1.0000\n",
      "Epoch 36/1000\n",
      "60/60 [==============================] - 0s 839us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 5.1156e-04 - val_accuracy: 1.0000\n",
      "Epoch 37/1000\n",
      "60/60 [==============================] - 0s 811us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 8.6352e-04 - val_accuracy: 1.0000\n",
      "Epoch 38/1000\n",
      "60/60 [==============================] - 0s 815us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 4.8658e-04 - val_accuracy: 1.0000\n",
      "Epoch 39/1000\n",
      "60/60 [==============================] - 0s 834us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 7.0466e-04 - val_accuracy: 1.0000\n",
      "Epoch 40/1000\n",
      "60/60 [==============================] - 0s 776us/step - loss: 8.4633e-04 - accuracy: 1.0000 - val_loss: 4.8906e-04 - val_accuracy: 1.0000\n",
      "Epoch 41/1000\n",
      "60/60 [==============================] - 0s 798us/step - loss: 8.5709e-04 - accuracy: 1.0000 - val_loss: 8.0609e-04 - val_accuracy: 1.0000\n",
      "Epoch 42/1000\n",
      "60/60 [==============================] - 0s 828us/step - loss: 7.6894e-04 - accuracy: 1.0000 - val_loss: 4.8582e-04 - val_accuracy: 1.0000\n",
      "Epoch 43/1000\n",
      "60/60 [==============================] - 0s 811us/step - loss: 5.7868e-04 - accuracy: 1.0000 - val_loss: 4.2642e-04 - val_accuracy: 1.0000\n",
      "Epoch 44/1000\n",
      "60/60 [==============================] - 0s 817us/step - loss: 7.2593e-04 - accuracy: 1.0000 - val_loss: 6.4466e-04 - val_accuracy: 1.0000\n",
      "Epoch 45/1000\n",
      "60/60 [==============================] - 0s 845us/step - loss: 5.9222e-04 - accuracy: 1.0000 - val_loss: 3.4407e-04 - val_accuracy: 1.0000\n",
      "Epoch 46/1000\n",
      "60/60 [==============================] - 0s 878us/step - loss: 4.7260e-04 - accuracy: 1.0000 - val_loss: 2.6440e-04 - val_accuracy: 1.0000\n",
      "Epoch 47/1000\n",
      "60/60 [==============================] - 0s 918us/step - loss: 5.3083e-04 - accuracy: 1.0000 - val_loss: 2.0993e-04 - val_accuracy: 1.0000\n",
      "Epoch 48/1000\n",
      "60/60 [==============================] - 0s 845us/step - loss: 4.0361e-04 - accuracy: 1.0000 - val_loss: 2.8087e-04 - val_accuracy: 1.0000\n",
      "Epoch 49/1000\n",
      "60/60 [==============================] - 0s 845us/step - loss: 4.4646e-04 - accuracy: 1.0000 - val_loss: 2.1636e-04 - val_accuracy: 1.0000\n",
      "Epoch 50/1000\n",
      "60/60 [==============================] - 0s 760us/step - loss: 3.8954e-04 - accuracy: 1.0000 - val_loss: 3.2555e-04 - val_accuracy: 1.0000\n",
      "Epoch 51/1000\n",
      "60/60 [==============================] - 0s 797us/step - loss: 4.7641e-04 - accuracy: 1.0000 - val_loss: 1.8860e-04 - val_accuracy: 1.0000\n",
      "Epoch 52/1000\n",
      "60/60 [==============================] - 0s 845us/step - loss: 3.3079e-04 - accuracy: 1.0000 - val_loss: 2.7377e-04 - val_accuracy: 1.0000\n",
      "Epoch 53/1000\n",
      "60/60 [==============================] - 0s 895us/step - loss: 2.6722e-04 - accuracy: 1.0000 - val_loss: 3.3948e-04 - val_accuracy: 1.0000\n",
      "Epoch 54/1000\n",
      "60/60 [==============================] - 0s 940us/step - loss: 2.0439e-04 - accuracy: 1.0000 - val_loss: 8.9147e-05 - val_accuracy: 1.0000\n",
      "Epoch 55/1000\n",
      "60/60 [==============================] - 0s 903us/step - loss: 4.0915e-04 - accuracy: 1.0000 - val_loss: 1.4516e-04 - val_accuracy: 1.0000\n",
      "Epoch 56/1000\n",
      "60/60 [==============================] - 0s 873us/step - loss: 2.4267e-04 - accuracy: 1.0000 - val_loss: 8.1409e-05 - val_accuracy: 1.0000\n",
      "Epoch 57/1000\n",
      "60/60 [==============================] - 0s 932us/step - loss: 2.1408e-04 - accuracy: 1.0000 - val_loss: 4.6751e-05 - val_accuracy: 1.0000\n",
      "Epoch 58/1000\n",
      "60/60 [==============================] - 0s 794us/step - loss: 1.8507e-04 - accuracy: 1.0000 - val_loss: 1.5456e-04 - val_accuracy: 1.0000\n",
      "Epoch 59/1000\n",
      "60/60 [==============================] - 0s 760us/step - loss: 1.7197e-04 - accuracy: 1.0000 - val_loss: 1.0918e-04 - val_accuracy: 1.0000\n",
      "Epoch 60/1000\n",
      "60/60 [==============================] - 0s 760us/step - loss: 1.4700e-04 - accuracy: 1.0000 - val_loss: 7.9404e-05 - val_accuracy: 1.0000\n",
      "Epoch 61/1000\n",
      "60/60 [==============================] - 0s 786us/step - loss: 1.0782e-04 - accuracy: 1.0000 - val_loss: 2.4433e-05 - val_accuracy: 1.0000\n",
      "Epoch 62/1000\n",
      "60/60 [==============================] - 0s 788us/step - loss: 1.8413e-04 - accuracy: 1.0000 - val_loss: 3.5866e-05 - val_accuracy: 1.0000\n",
      "Epoch 63/1000\n",
      "60/60 [==============================] - 0s 811us/step - loss: 1.5045e-04 - accuracy: 1.0000 - val_loss: 6.5295e-05 - val_accuracy: 1.0000\n",
      "Epoch 64/1000\n",
      "60/60 [==============================] - 0s 828us/step - loss: 1.1734e-04 - accuracy: 1.0000 - val_loss: 8.7302e-05 - val_accuracy: 1.0000\n",
      "Epoch 65/1000\n",
      "60/60 [==============================] - 0s 828us/step - loss: 8.1830e-05 - accuracy: 1.0000 - val_loss: 2.5320e-05 - val_accuracy: 1.0000\n",
      "Epoch 66/1000\n",
      "60/60 [==============================] - 0s 845us/step - loss: 1.0932e-04 - accuracy: 1.0000 - val_loss: 6.2649e-05 - val_accuracy: 1.0000\n",
      "Epoch 67/1000\n",
      "60/60 [==============================] - 0s 895us/step - loss: 6.6920e-05 - accuracy: 1.0000 - val_loss: 4.0011e-05 - val_accuracy: 1.0000\n",
      "Epoch 68/1000\n",
      "60/60 [==============================] - 0s 862us/step - loss: 1.0015e-04 - accuracy: 1.0000 - val_loss: 6.4470e-05 - val_accuracy: 1.0000\n",
      "Epoch 69/1000\n",
      "60/60 [==============================] - 0s 864us/step - loss: 8.2058e-05 - accuracy: 1.0000 - val_loss: 4.8083e-05 - val_accuracy: 1.0000\n",
      "Epoch 70/1000\n",
      "60/60 [==============================] - 0s 811us/step - loss: 4.9336e-05 - accuracy: 1.0000 - val_loss: 1.0569e-05 - val_accuracy: 1.0000\n",
      "Epoch 71/1000\n",
      "60/60 [==============================] - 0s 762us/step - loss: 1.0369e-04 - accuracy: 1.0000 - val_loss: 3.1084e-05 - val_accuracy: 1.0000\n",
      "Epoch 72/1000\n",
      "60/60 [==============================] - 0s 828us/step - loss: 4.6078e-05 - accuracy: 1.0000 - val_loss: 1.4436e-05 - val_accuracy: 1.0000\n",
      "Epoch 73/1000\n",
      "60/60 [==============================] - 0s 836us/step - loss: 7.6451e-05 - accuracy: 1.0000 - val_loss: 1.9804e-05 - val_accuracy: 1.0000\n",
      "Epoch 74/1000\n",
      "60/60 [==============================] - 0s 861us/step - loss: 1.0910e-04 - accuracy: 1.0000 - val_loss: 1.7781e-05 - val_accuracy: 1.0000\n",
      "Epoch 75/1000\n",
      "60/60 [==============================] - 0s 785us/step - loss: 3.8929e-05 - accuracy: 1.0000 - val_loss: 1.3956e-05 - val_accuracy: 1.0000\n",
      "Epoch 76/1000\n",
      "60/60 [==============================] - 0s 862us/step - loss: 4.7462e-05 - accuracy: 1.0000 - val_loss: 1.9207e-05 - val_accuracy: 1.0000\n",
      "Epoch 77/1000\n",
      "60/60 [==============================] - 0s 775us/step - loss: 4.5048e-05 - accuracy: 1.0000 - val_loss: 1.9254e-05 - val_accuracy: 1.0000\n",
      "Epoch 78/1000\n",
      "60/60 [==============================] - 0s 836us/step - loss: 3.2406e-05 - accuracy: 1.0000 - val_loss: 1.4203e-05 - val_accuracy: 1.0000\n",
      "Epoch 79/1000\n",
      "60/60 [==============================] - 0s 786us/step - loss: 3.1403e-05 - accuracy: 1.0000 - val_loss: 2.4014e-05 - val_accuracy: 1.0000\n",
      "Epoch 80/1000\n",
      "60/60 [==============================] - 0s 882us/step - loss: 2.6897e-05 - accuracy: 1.0000 - val_loss: 6.8974e-06 - val_accuracy: 1.0000\n",
      "Epoch 81/1000\n",
      "60/60 [==============================] - 0s 862us/step - loss: 4.8298e-05 - accuracy: 1.0000 - val_loss: 1.2360e-05 - val_accuracy: 1.0000\n",
      "Epoch 82/1000\n",
      "60/60 [==============================] - 0s 845us/step - loss: 2.3927e-05 - accuracy: 1.0000 - val_loss: 2.7520e-05 - val_accuracy: 1.0000\n",
      "Epoch 83/1000\n",
      "60/60 [==============================] - 0s 840us/step - loss: 2.0955e-05 - accuracy: 1.0000 - val_loss: 1.6579e-05 - val_accuracy: 1.0000\n",
      "Epoch 84/1000\n",
      "60/60 [==============================] - 0s 811us/step - loss: 1.4644e-05 - accuracy: 1.0000 - val_loss: 3.0313e-06 - val_accuracy: 1.0000\n",
      "Epoch 85/1000\n",
      "60/60 [==============================] - 0s 811us/step - loss: 4.8369e-05 - accuracy: 1.0000 - val_loss: 7.2851e-06 - val_accuracy: 1.0000\n",
      "Epoch 86/1000\n",
      "60/60 [==============================] - 0s 777us/step - loss: 2.0623e-05 - accuracy: 1.0000 - val_loss: 1.2215e-05 - val_accuracy: 1.0000\n",
      "Epoch 87/1000\n",
      "60/60 [==============================] - 0s 760us/step - loss: 1.3020e-05 - accuracy: 1.0000 - val_loss: 3.9447e-06 - val_accuracy: 1.0000\n",
      "Epoch 88/1000\n",
      "60/60 [==============================] - 0s 777us/step - loss: 1.5788e-05 - accuracy: 1.0000 - val_loss: 7.1835e-06 - val_accuracy: 1.0000\n",
      "Epoch 89/1000\n",
      "60/60 [==============================] - 0s 794us/step - loss: 1.1114e-05 - accuracy: 1.0000 - val_loss: 3.9193e-06 - val_accuracy: 1.0000\n",
      "Epoch 90/1000\n",
      "60/60 [==============================] - 0s 794us/step - loss: 1.3832e-05 - accuracy: 1.0000 - val_loss: 6.4804e-06 - val_accuracy: 1.0000\n",
      "Epoch 91/1000\n",
      "60/60 [==============================] - 0s 777us/step - loss: 8.0536e-06 - accuracy: 1.0000 - val_loss: 2.6107e-06 - val_accuracy: 1.0000\n",
      "Epoch 92/1000\n",
      "60/60 [==============================] - 0s 913us/step - loss: 1.1953e-05 - accuracy: 1.0000 - val_loss: 1.6216e-06 - val_accuracy: 1.0000\n",
      "Epoch 93/1000\n",
      "60/60 [==============================] - 0s 855us/step - loss: 1.4718e-05 - accuracy: 1.0000 - val_loss: 4.3253e-06 - val_accuracy: 1.0000\n",
      "Epoch 94/1000\n",
      "60/60 [==============================] - 0s 913us/step - loss: 4.8856e-06 - accuracy: 1.0000 - val_loss: 8.1093e-07 - val_accuracy: 1.0000\n",
      "Epoch 95/1000\n",
      "60/60 [==============================] - 0s 863us/step - loss: 9.9424e-06 - accuracy: 1.0000 - val_loss: 5.6650e-06 - val_accuracy: 1.0000\n",
      "Epoch 96/1000\n",
      "60/60 [==============================] - 0s 793us/step - loss: 5.8494e-06 - accuracy: 1.0000 - val_loss: 3.9458e-06 - val_accuracy: 1.0000\n",
      "Epoch 97/1000\n",
      "60/60 [==============================] - 0s 836us/step - loss: 4.8409e-06 - accuracy: 1.0000 - val_loss: 1.7639e-06 - val_accuracy: 1.0000\n",
      "Epoch 98/1000\n",
      "60/60 [==============================] - 0s 828us/step - loss: 3.9392e-06 - accuracy: 1.0000 - val_loss: 9.0277e-07 - val_accuracy: 1.0000\n",
      "Epoch 99/1000\n",
      "60/60 [==============================] - 0s 802us/step - loss: 6.3949e-06 - accuracy: 1.0000 - val_loss: 2.3978e-06 - val_accuracy: 1.0000\n",
      "Epoch 100/1000\n",
      "60/60 [==============================] - 0s 839us/step - loss: 3.0393e-06 - accuracy: 1.0000 - val_loss: 9.1958e-07 - val_accuracy: 1.0000\n",
      "Epoch 101/1000\n",
      "60/60 [==============================] - 0s 871us/step - loss: 4.9939e-06 - accuracy: 1.0000 - val_loss: 6.1101e-06 - val_accuracy: 1.0000\n",
      "Epoch 102/1000\n",
      "60/60 [==============================] - 0s 862us/step - loss: 3.3295e-06 - accuracy: 1.0000 - val_loss: 6.1569e-06 - val_accuracy: 1.0000\n",
      "Epoch 103/1000\n",
      "60/60 [==============================] - 0s 895us/step - loss: 2.6024e-06 - accuracy: 1.0000 - val_loss: 1.1393e-06 - val_accuracy: 1.0000\n",
      "Epoch 104/1000\n",
      "60/60 [==============================] - 0s 836us/step - loss: 3.5668e-06 - accuracy: 1.0000 - val_loss: 1.1729e-06 - val_accuracy: 1.0000\n",
      "Epoch 105/1000\n",
      "60/60 [==============================] - 0s 786us/step - loss: 5.0002e-06 - accuracy: 1.0000 - val_loss: 1.2899e-06 - val_accuracy: 1.0000\n",
      "Epoch 106/1000\n",
      "60/60 [==============================] - 0s 795us/step - loss: 1.8160e-06 - accuracy: 1.0000 - val_loss: 5.5794e-07 - val_accuracy: 1.0000\n",
      "Epoch 107/1000\n",
      "60/60 [==============================] - 0s 828us/step - loss: 2.4523e-06 - accuracy: 1.0000 - val_loss: 2.3412e-06 - val_accuracy: 1.0000\n",
      "Epoch 108/1000\n",
      "60/60 [==============================] - 0s 794us/step - loss: 1.9438e-06 - accuracy: 1.0000 - val_loss: 9.7776e-07 - val_accuracy: 1.0000\n",
      "Epoch 109/1000\n",
      "60/60 [==============================] - 0s 812us/step - loss: 1.2735e-06 - accuracy: 1.0000 - val_loss: 1.7952e-06 - val_accuracy: 1.0000\n",
      "Epoch 110/1000\n",
      "60/60 [==============================] - 0s 863us/step - loss: 1.5354e-06 - accuracy: 1.0000 - val_loss: 1.1486e-06 - val_accuracy: 1.0000\n",
      "Epoch 111/1000\n",
      "60/60 [==============================] - 0s 862us/step - loss: 1.1580e-06 - accuracy: 1.0000 - val_loss: 3.3432e-07 - val_accuracy: 1.0000\n",
      "Epoch 112/1000\n",
      "60/60 [==============================] - 0s 878us/step - loss: 7.3575e-07 - accuracy: 1.0000 - val_loss: 2.3697e-07 - val_accuracy: 1.0000\n",
      "Epoch 113/1000\n",
      "60/60 [==============================] - 0s 838us/step - loss: 1.1935e-06 - accuracy: 1.0000 - val_loss: 7.4964e-07 - val_accuracy: 1.0000\n",
      "Epoch 114/1000\n",
      "60/60 [==============================] - 0s 837us/step - loss: 1.1159e-06 - accuracy: 1.0000 - val_loss: 9.9780e-07 - val_accuracy: 1.0000\n",
      "Epoch 115/1000\n",
      "60/60 [==============================] - 0s 827us/step - loss: 8.8702e-07 - accuracy: 1.0000 - val_loss: 9.6682e-07 - val_accuracy: 1.0000\n",
      "Epoch 116/1000\n",
      "60/60 [==============================] - 0s 871us/step - loss: 6.9453e-07 - accuracy: 1.0000 - val_loss: 8.1886e-07 - val_accuracy: 1.0000\n",
      "Epoch 117/1000\n",
      "60/60 [==============================] - 0s 878us/step - loss: 8.9251e-07 - accuracy: 1.0000 - val_loss: 8.8574e-07 - val_accuracy: 1.0000\n",
      "Epoch 118/1000\n",
      "60/60 [==============================] - 0s 886us/step - loss: 5.5921e-07 - accuracy: 1.0000 - val_loss: 3.9919e-07 - val_accuracy: 1.0000\n",
      "Epoch 119/1000\n",
      "60/60 [==============================] - 0s 794us/step - loss: 7.1370e-07 - accuracy: 1.0000 - val_loss: 4.0168e-07 - val_accuracy: 1.0000\n",
      "Epoch 120/1000\n",
      "60/60 [==============================] - 0s 872us/step - loss: 4.5660e-07 - accuracy: 1.0000 - val_loss: 5.2657e-08 - val_accuracy: 1.0000\n",
      "Epoch 121/1000\n",
      "60/60 [==============================] - 0s 783us/step - loss: 7.6571e-07 - accuracy: 1.0000 - val_loss: 4.9966e-07 - val_accuracy: 1.0000\n",
      "Epoch 122/1000\n",
      "60/60 [==============================] - 0s 946us/step - loss: 4.3981e-07 - accuracy: 1.0000 - val_loss: 1.0923e-07 - val_accuracy: 1.0000\n",
      "Epoch 123/1000\n",
      "60/60 [==============================] - 0s 921us/step - loss: 3.9924e-07 - accuracy: 1.0000 - val_loss: 1.3711e-07 - val_accuracy: 1.0000\n",
      "Epoch 124/1000\n",
      "60/60 [==============================] - 0s 916us/step - loss: 1.6581e-07 - accuracy: 1.0000 - val_loss: 1.6065e-06 - val_accuracy: 1.0000\n",
      "Epoch 125/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.0963e-07 - accuracy: 1.0000 - val_loss: 2.3823e-08 - val_accuracy: 1.0000\n",
      "Epoch 126/1000\n",
      "60/60 [==============================] - 0s 981us/step - loss: 2.2951e-07 - accuracy: 1.0000 - val_loss: 6.5724e-08 - val_accuracy: 1.0000\n",
      "Epoch 127/1000\n",
      "60/60 [==============================] - 0s 895us/step - loss: 1.7525e-07 - accuracy: 1.0000 - val_loss: 1.1083e-08 - val_accuracy: 1.0000\n",
      "Epoch 128/1000\n",
      "60/60 [==============================] - 0s 895us/step - loss: 2.3650e-07 - accuracy: 1.0000 - val_loss: 2.9053e-07 - val_accuracy: 1.0000\n",
      "Epoch 129/1000\n",
      "60/60 [==============================] - 0s 929us/step - loss: 1.7339e-07 - accuracy: 1.0000 - val_loss: 4.6931e-08 - val_accuracy: 1.0000\n",
      "Epoch 130/1000\n",
      "60/60 [==============================] - 0s 948us/step - loss: 1.6223e-07 - accuracy: 1.0000 - val_loss: 3.2119e-07 - val_accuracy: 1.0000\n",
      "Epoch 131/1000\n",
      "60/60 [==============================] - 0s 844us/step - loss: 1.4472e-07 - accuracy: 1.0000 - val_loss: 2.2458e-08 - val_accuracy: 1.0000\n",
      "Epoch 132/1000\n",
      "60/60 [==============================] - 0s 828us/step - loss: 1.6632e-07 - accuracy: 1.0000 - val_loss: 1.0097e-07 - val_accuracy: 1.0000\n",
      "Epoch 133/1000\n",
      "60/60 [==============================] - 0s 828us/step - loss: 1.1420e-07 - accuracy: 1.0000 - val_loss: 2.7210e-07 - val_accuracy: 1.0000\n",
      "Epoch 134/1000\n",
      "60/60 [==============================] - 0s 811us/step - loss: 1.0450e-07 - accuracy: 1.0000 - val_loss: 3.3569e-08 - val_accuracy: 1.0000\n",
      "Epoch 135/1000\n",
      "60/60 [==============================] - 0s 794us/step - loss: 7.9883e-08 - accuracy: 1.0000 - val_loss: 1.9287e-08 - val_accuracy: 1.0000\n",
      "Epoch 136/1000\n",
      "60/60 [==============================] - 0s 878us/step - loss: 1.0073e-07 - accuracy: 1.0000 - val_loss: 2.4015e-08 - val_accuracy: 1.0000\n",
      "Epoch 137/1000\n",
      "60/60 [==============================] - 0s 845us/step - loss: 7.6819e-08 - accuracy: 1.0000 - val_loss: 1.3745e-07 - val_accuracy: 1.0000\n",
      "Epoch 138/1000\n",
      "60/60 [==============================] - 0s 884us/step - loss: 7.2386e-08 - accuracy: 1.0000 - val_loss: 1.8006e-08 - val_accuracy: 1.0000\n",
      "Epoch 139/1000\n",
      "60/60 [==============================] - 0s 921us/step - loss: 6.7321e-08 - accuracy: 1.0000 - val_loss: 1.7019e-07 - val_accuracy: 1.0000\n",
      "Epoch 140/1000\n",
      "60/60 [==============================] - 0s 811us/step - loss: 5.3412e-08 - accuracy: 1.0000 - val_loss: 1.2285e-07 - val_accuracy: 1.0000\n",
      "Epoch 141/1000\n",
      "60/60 [==============================] - 0s 832us/step - loss: 7.1926e-08 - accuracy: 1.0000 - val_loss: 6.8185e-08 - val_accuracy: 1.0000\n",
      "Epoch 142/1000\n",
      "60/60 [==============================] - 0s 845us/step - loss: 3.1265e-08 - accuracy: 1.0000 - val_loss: 6.2761e-09 - val_accuracy: 1.0000\n",
      "Epoch 143/1000\n",
      "60/60 [==============================] - 0s 828us/step - loss: 6.2974e-08 - accuracy: 1.0000 - val_loss: 1.3511e-08 - val_accuracy: 1.0000\n",
      "Epoch 144/1000\n",
      "60/60 [==============================] - 0s 794us/step - loss: 4.4606e-08 - accuracy: 1.0000 - val_loss: 1.1338e-08 - val_accuracy: 1.0000\n",
      "Epoch 145/1000\n",
      "60/60 [==============================] - 0s 777us/step - loss: 4.1124e-08 - accuracy: 1.0000 - val_loss: 1.2641e-08 - val_accuracy: 1.0000\n",
      "Epoch 146/1000\n",
      "60/60 [==============================] - 0s 773us/step - loss: 5.0011e-08 - accuracy: 1.0000 - val_loss: 3.9598e-08 - val_accuracy: 1.0000\n",
      "Epoch 147/1000\n",
      "60/60 [==============================] - 0s 782us/step - loss: 3.4007e-08 - accuracy: 1.0000 - val_loss: 1.9665e-08 - val_accuracy: 1.0000\n",
      "Epoch 148/1000\n",
      "60/60 [==============================] - 0s 854us/step - loss: 3.1433e-08 - accuracy: 1.0000 - val_loss: 1.0312e-08 - val_accuracy: 1.0000\n",
      "Epoch 149/1000\n",
      "60/60 [==============================] - 0s 777us/step - loss: 3.3760e-08 - accuracy: 1.0000 - val_loss: 6.6195e-08 - val_accuracy: 1.0000\n",
      "Epoch 150/1000\n",
      "60/60 [==============================] - 0s 760us/step - loss: 2.6904e-08 - accuracy: 1.0000 - val_loss: 2.6771e-08 - val_accuracy: 1.0000\n",
      "Epoch 151/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.2940e-08 - accuracy: 1.0000 - val_loss: 1.0588e-08 - val_accuracy: 1.0000\n",
      "Epoch 152/1000\n",
      "60/60 [==============================] - 0s 822us/step - loss: 2.4008e-08 - accuracy: 1.0000 - val_loss: 5.0833e-09 - val_accuracy: 1.0000\n",
      "Epoch 153/1000\n",
      "60/60 [==============================] - 0s 898us/step - loss: 2.5166e-08 - accuracy: 1.0000 - val_loss: 1.0875e-08 - val_accuracy: 1.0000\n",
      "Epoch 154/1000\n",
      "60/60 [==============================] - 0s 831us/step - loss: 1.9860e-08 - accuracy: 1.0000 - val_loss: 1.5911e-08 - val_accuracy: 1.0000\n",
      "Epoch 155/1000\n",
      "60/60 [==============================] - 0s 862us/step - loss: 1.9654e-08 - accuracy: 1.0000 - val_loss: 1.1522e-08 - val_accuracy: 1.0000\n",
      "Epoch 156/1000\n",
      "60/60 [==============================] - 0s 894us/step - loss: 1.6710e-08 - accuracy: 1.0000 - val_loss: 7.9722e-09 - val_accuracy: 1.0000\n",
      "Epoch 157/1000\n",
      "60/60 [==============================] - 0s 777us/step - loss: 1.0744e-08 - accuracy: 1.0000 - val_loss: 5.6274e-08 - val_accuracy: 1.0000\n",
      "Epoch 158/1000\n",
      "60/60 [==============================] - 0s 828us/step - loss: 1.6334e-08 - accuracy: 1.0000 - val_loss: 1.1662e-08 - val_accuracy: 1.0000\n",
      "Epoch 159/1000\n",
      "60/60 [==============================] - 0s 794us/step - loss: 1.3038e-08 - accuracy: 1.0000 - val_loss: 5.3332e-09 - val_accuracy: 1.0000\n",
      "Epoch 160/1000\n",
      "60/60 [==============================] - 0s 760us/step - loss: 9.1862e-09 - accuracy: 1.0000 - val_loss: 5.1167e-09 - val_accuracy: 1.0000\n",
      "Epoch 161/1000\n",
      "60/60 [==============================] - 0s 760us/step - loss: 1.3354e-08 - accuracy: 1.0000 - val_loss: 8.7063e-09 - val_accuracy: 1.0000\n",
      "Epoch 162/1000\n",
      "60/60 [==============================] - 0s 781us/step - loss: 1.0047e-08 - accuracy: 1.0000 - val_loss: 2.3303e-08 - val_accuracy: 1.0000\n",
      "Epoch 163/1000\n",
      "60/60 [==============================] - 0s 758us/step - loss: 9.7630e-09 - accuracy: 1.0000 - val_loss: 4.0277e-09 - val_accuracy: 1.0000\n",
      "Epoch 164/1000\n",
      "60/60 [==============================] - 0s 811us/step - loss: 1.0142e-08 - accuracy: 1.0000 - val_loss: 1.7980e-08 - val_accuracy: 1.0000\n",
      "Epoch 165/1000\n",
      "60/60 [==============================] - 0s 794us/step - loss: 8.5331e-09 - accuracy: 1.0000 - val_loss: 4.3106e-09 - val_accuracy: 1.0000\n",
      "Epoch 166/1000\n",
      "60/60 [==============================] - 0s 849us/step - loss: 9.0099e-09 - accuracy: 1.0000 - val_loss: 3.9404e-09 - val_accuracy: 1.0000\n",
      "Epoch 167/1000\n",
      "60/60 [==============================] - 0s 791us/step - loss: 7.4661e-09 - accuracy: 1.0000 - val_loss: 3.2339e-09 - val_accuracy: 1.0000\n",
      "Epoch 168/1000\n",
      "60/60 [==============================] - 0s 811us/step - loss: 8.5824e-09 - accuracy: 1.0000 - val_loss: 1.5583e-08 - val_accuracy: 1.0000\n",
      "Epoch 169/1000\n",
      "60/60 [==============================] - 0s 953us/step - loss: 6.8104e-09 - accuracy: 1.0000 - val_loss: 3.5145e-09 - val_accuracy: 1.0000\n",
      "Epoch 170/1000\n",
      "60/60 [==============================] - 0s 828us/step - loss: 5.9678e-09 - accuracy: 1.0000 - val_loss: 1.4874e-08 - val_accuracy: 1.0000\n",
      "Epoch 171/1000\n",
      "60/60 [==============================] - 0s 828us/step - loss: 6.9714e-09 - accuracy: 1.0000 - val_loss: 1.5277e-08 - val_accuracy: 1.0000\n",
      "Epoch 172/1000\n",
      "60/60 [==============================] - 0s 824us/step - loss: 6.0841e-09 - accuracy: 1.0000 - val_loss: 1.6591e-08 - val_accuracy: 1.0000\n",
      "Epoch 173/1000\n",
      "60/60 [==============================] - 0s 840us/step - loss: 6.8248e-09 - accuracy: 1.0000 - val_loss: 7.1761e-09 - val_accuracy: 1.0000\n",
      "Epoch 174/1000\n",
      "60/60 [==============================] - 0s 942us/step - loss: 5.6529e-09 - accuracy: 1.0000 - val_loss: 3.7365e-09 - val_accuracy: 1.0000\n",
      "Epoch 175/1000\n",
      "60/60 [==============================] - 0s 777us/step - loss: 5.8003e-09 - accuracy: 1.0000 - val_loss: 8.0024e-09 - val_accuracy: 1.0000\n",
      "Epoch 176/1000\n",
      "60/60 [==============================] - 0s 828us/step - loss: 4.8798e-09 - accuracy: 1.0000 - val_loss: 4.1607e-09 - val_accuracy: 1.0000\n",
      "Epoch 177/1000\n",
      "60/60 [==============================] - 0s 819us/step - loss: 3.9134e-09 - accuracy: 1.0000 - val_loss: 1.9632e-09 - val_accuracy: 1.0000\n",
      "Epoch 178/1000\n",
      "60/60 [==============================] - 0s 847us/step - loss: 5.1771e-09 - accuracy: 1.0000 - val_loss: 6.2520e-09 - val_accuracy: 1.0000\n",
      "Epoch 179/1000\n",
      "60/60 [==============================] - 0s 743us/step - loss: 4.6532e-09 - accuracy: 1.0000 - val_loss: 1.0875e-08 - val_accuracy: 1.0000\n",
      "Epoch 180/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 4.4128e-09 - accuracy: 1.0000 - val_loss: 3.1487e-09 - val_accuracy: 1.0000\n",
      "Epoch 181/1000\n",
      "60/60 [==============================] - 0s 825us/step - loss: 4.2099e-09 - accuracy: 1.0000 - val_loss: 1.1458e-08 - val_accuracy: 1.0000\n",
      "Epoch 182/1000\n",
      "60/60 [==============================] - 0s 803us/step - loss: 4.0150e-09 - accuracy: 1.0000 - val_loss: 3.2829e-09 - val_accuracy: 1.0000\n",
      "Epoch 183/1000\n",
      "60/60 [==============================] - 0s 856us/step - loss: 4.0289e-09 - accuracy: 1.0000 - val_loss: 2.3292e-09 - val_accuracy: 1.0000\n",
      "Epoch 184/1000\n",
      "60/60 [==============================] - 0s 740us/step - loss: 4.2402e-09 - accuracy: 1.0000 - val_loss: 6.0089e-09 - val_accuracy: 1.0000\n",
      "Epoch 185/1000\n",
      "60/60 [==============================] - 0s 828us/step - loss: 3.9538e-09 - accuracy: 1.0000 - val_loss: 3.1779e-09 - val_accuracy: 1.0000\n",
      "Epoch 186/1000\n",
      "60/60 [==============================] - 0s 804us/step - loss: 3.5739e-09 - accuracy: 1.0000 - val_loss: 2.2067e-09 - val_accuracy: 1.0000\n",
      "Epoch 187/1000\n",
      "60/60 [==============================] - 0s 775us/step - loss: 3.3814e-09 - accuracy: 1.0000 - val_loss: 6.1911e-09 - val_accuracy: 1.0000\n",
      "Epoch 188/1000\n",
      "60/60 [==============================] - 0s 770us/step - loss: 3.5400e-09 - accuracy: 1.0000 - val_loss: 4.8466e-09 - val_accuracy: 1.0000\n",
      "Epoch 189/1000\n",
      "60/60 [==============================] - 0s 815us/step - loss: 3.3081e-09 - accuracy: 1.0000 - val_loss: 2.2845e-09 - val_accuracy: 1.0000\n",
      "Epoch 190/1000\n",
      "60/60 [==============================] - 0s 840us/step - loss: 3.0382e-09 - accuracy: 1.0000 - val_loss: 2.9979e-09 - val_accuracy: 1.0000\n",
      "Epoch 191/1000\n",
      "60/60 [==============================] - 0s 794us/step - loss: 2.8297e-09 - accuracy: 1.0000 - val_loss: 5.4309e-09 - val_accuracy: 1.0000\n",
      "Epoch 192/1000\n",
      "60/60 [==============================] - 0s 732us/step - loss: 3.1925e-09 - accuracy: 1.0000 - val_loss: 6.1613e-09 - val_accuracy: 1.0000\n",
      "Epoch 193/1000\n",
      "60/60 [==============================] - 0s 810us/step - loss: 2.7937e-09 - accuracy: 1.0000 - val_loss: 1.9207e-09 - val_accuracy: 1.0000\n",
      "Epoch 194/1000\n",
      "60/60 [==============================] - 0s 777us/step - loss: 3.0385e-09 - accuracy: 1.0000 - val_loss: 2.4971e-09 - val_accuracy: 1.0000\n",
      "Epoch 195/1000\n",
      "60/60 [==============================] - 0s 772us/step - loss: 2.8186e-09 - accuracy: 1.0000 - val_loss: 2.7486e-09 - val_accuracy: 1.0000\n",
      "Epoch 196/1000\n",
      "60/60 [==============================] - 0s 894us/step - loss: 2.6931e-09 - accuracy: 1.0000 - val_loss: 3.6374e-09 - val_accuracy: 1.0000\n",
      "Epoch 197/1000\n",
      "60/60 [==============================] - 0s 862us/step - loss: 2.6446e-09 - accuracy: 1.0000 - val_loss: 2.7114e-09 - val_accuracy: 1.0000\n",
      "Epoch 198/1000\n",
      "60/60 [==============================] - 0s 840us/step - loss: 1.9489e-09 - accuracy: 1.0000 - val_loss: 1.2585e-09 - val_accuracy: 1.0000\n",
      "Epoch 199/1000\n",
      "60/60 [==============================] - 0s 816us/step - loss: 2.7728e-09 - accuracy: 1.0000 - val_loss: 3.2033e-09 - val_accuracy: 1.0000\n",
      "Epoch 200/1000\n",
      "60/60 [==============================] - 0s 820us/step - loss: 2.0621e-09 - accuracy: 1.0000 - val_loss: 2.5892e-09 - val_accuracy: 1.0000\n",
      "Epoch 201/1000\n",
      "60/60 [==============================] - 0s 828us/step - loss: 2.4054e-09 - accuracy: 1.0000 - val_loss: 2.1486e-09 - val_accuracy: 1.0000\n",
      "Epoch 202/1000\n",
      "60/60 [==============================] - 0s 845us/step - loss: 2.3697e-09 - accuracy: 1.0000 - val_loss: 3.3460e-09 - val_accuracy: 1.0000\n",
      "Epoch 203/1000\n",
      "60/60 [==============================] - 0s 852us/step - loss: 2.2527e-09 - accuracy: 1.0000 - val_loss: 1.4275e-09 - val_accuracy: 1.0000\n",
      "Epoch 204/1000\n",
      "60/60 [==============================] - 0s 763us/step - loss: 2.3242e-09 - accuracy: 1.0000 - val_loss: 2.1460e-09 - val_accuracy: 1.0000\n",
      "Epoch 205/1000\n",
      "60/60 [==============================] - 0s 1ms/step - loss: 2.2332e-09 - accuracy: 1.0000 - val_loss: 2.0676e-09 - val_accuracy: 1.0000\n",
      "Epoch 206/1000\n",
      "60/60 [==============================] - 0s 828us/step - loss: 1.9387e-09 - accuracy: 1.0000 - val_loss: 3.6715e-09 - val_accuracy: 1.0000\n",
      "Epoch 207/1000\n",
      "60/60 [==============================] - 0s 828us/step - loss: 1.9863e-09 - accuracy: 1.0000 - val_loss: 1.4847e-09 - val_accuracy: 1.0000\n",
      "Epoch 208/1000\n",
      "60/60 [==============================] - 0s 811us/step - loss: 1.8323e-09 - accuracy: 1.0000 - val_loss: 3.8792e-09 - val_accuracy: 1.0000\n",
      "Epoch 209/1000\n",
      "60/60 [==============================] - 0s 856us/step - loss: 1.8581e-09 - accuracy: 1.0000 - val_loss: 1.2594e-09 - val_accuracy: 1.0000\n",
      "Epoch 210/1000\n",
      "60/60 [==============================] - 0s 863us/step - loss: 1.7855e-09 - accuracy: 1.0000 - val_loss: 3.6397e-09 - val_accuracy: 1.0000\n",
      "Epoch 211/1000\n",
      "60/60 [==============================] - 0s 847us/step - loss: 1.8506e-09 - accuracy: 1.0000 - val_loss: 1.5319e-09 - val_accuracy: 1.0000\n",
      "Epoch 212/1000\n",
      "60/60 [==============================] - 0s 841us/step - loss: 1.7106e-09 - accuracy: 1.0000 - val_loss: 1.4310e-09 - val_accuracy: 1.0000\n",
      "Epoch 213/1000\n",
      "60/60 [==============================] - 0s 815us/step - loss: 2.1176e-09 - accuracy: 1.0000 - val_loss: 1.4230e-09 - val_accuracy: 1.0000\n",
      "Epoch 214/1000\n",
      "60/60 [==============================] - 0s 822us/step - loss: 1.6158e-09 - accuracy: 1.0000 - val_loss: 1.8535e-09 - val_accuracy: 1.0000\n",
      "Epoch 215/1000\n",
      "60/60 [==============================] - 0s 782us/step - loss: 1.6810e-09 - accuracy: 1.0000 - val_loss: 2.9898e-09 - val_accuracy: 1.0000\n",
      "Epoch 216/1000\n",
      "60/60 [==============================] - 0s 818us/step - loss: 1.6333e-09 - accuracy: 1.0000 - val_loss: 1.4629e-09 - val_accuracy: 1.0000\n",
      "Epoch 217/1000\n",
      "60/60 [==============================] - 0s 874us/step - loss: 1.5863e-09 - accuracy: 1.0000 - val_loss: 1.5470e-09 - val_accuracy: 1.0000\n",
      "Epoch 218/1000\n",
      "60/60 [==============================] - 0s 878us/step - loss: 1.5360e-09 - accuracy: 1.0000 - val_loss: 1.2952e-09 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras import layers, models\n",
    "from keras import Input\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.random.set_seed(555)     #랜덤시드 555설정\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(24, activation='relu', input_shape=(search_train_x.shape[1],)))\n",
    "model.add(layers.Dense(12, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "callback_list = [\n",
    "  keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', # 모델의 검증 정확도 모니터링\n",
    "    patience=20, # 1 에포크보다 더 길게 향상되지 않으면 중단\n",
    "  )\n",
    "]\n",
    "# batch_size : batch_size만큼 보고 가중치를 업데이트 주겠다\n",
    "hist = model.fit(search_train_x, search_train_y, epochs=1000, batch_size=10, \n",
    "                 callbacks=callback_list, validation_data=(search_val_x, search_val_y)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "1SO7Am6Vmipf",
    "outputId": "76fb430f-5f3f-4528-f58c-1939b3cc75d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras.utils in c:\\users\\user\\anaconda3\\lib\\site-packages (1.0.13)\n",
      "Requirement already satisfied: Keras>=2.1.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from keras.utils) (2.6.0)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'plot_model' from 'keras.utils' (C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\utils\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-af71692f90bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#모델 그림 추가 예정\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pip install keras.utils'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'DNNmodel'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'plot_model' from 'keras.utils' (C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\utils\\__init__.py)"
     ]
    }
   ],
   "source": [
    "#모델 그림 추가 예정\n",
    "!pip install keras.utils\n",
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='DNNmodel', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = hist.history['accuracy']\n",
    "val_acc = hist.history['val_accuracy']\n",
    "\n",
    "plt.plot(acc, 'bo', label='Training acc')\n",
    "plt.plot(val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 849
    },
    "id": "JtjmJJXyoPvZ",
    "outputId": "f4b1bb38-5ccb-482c-fe5c-9c1e4cd3cf9e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>y_predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>2.069889e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0</td>\n",
       "      <td>9.587232e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>0</td>\n",
       "      <td>6.675882e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0</td>\n",
       "      <td>3.486414e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>0</td>\n",
       "      <td>2.483746e-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>7.452822e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>0</td>\n",
       "      <td>8.115517e-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label     y_predict\n",
       "9        0  2.069889e-19\n",
       "499      0  9.587232e-17\n",
       "891      1  1.000000e+00\n",
       "444      0  6.675882e-17\n",
       "123      0  3.486414e-17\n",
       "..     ...           ...\n",
       "381      0  2.483746e-21\n",
       "580      1  1.000000e+00\n",
       "33       0  7.452822e-11\n",
       "686      1  1.000000e+00\n",
       "410      0  8.115517e-20\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습 시각화 함수\n",
    "def learning_graph(hist):\n",
    "    fig, loss_ax = plt.subplots()\n",
    "    loss_ax.plot(hist.history['loss'],'g', label='train loss')\n",
    "    loss_ax.plot(hist.history['val_loss'],'b', label='val loss')\n",
    "    loss_ax.set_xlabel('epoch')\n",
    "    loss_ax.set_ylabel('loss')\n",
    "    loss_ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "learning_graph(hist)\n",
    "\n",
    "# 실제값, 예측값 그래프\n",
    "y_predict = model.predict(search_test_x) ####\n",
    "\n",
    "# 에러율 - Root Mean Squared Error\n",
    "# rmse = np.sqrt(mean_squared_error(y_predict, search_test_y))\n",
    "# print('RMSE: ',rmse.round(2))\n",
    "\n",
    "# r = explained_variance_score(search_test_y, y_predict)\n",
    "# print('R-Square: ',r.round(2))\n",
    "\n",
    "# fig, loss_ax = plt.subplots()\n",
    "# loss_ax.bar(search_test_y)\n",
    "# loss_ax.bar(y_predict)\n",
    "# loss_ax.legend(loc='upper left')\n",
    "# plt.show()\n",
    "\n",
    "df = pd.DataFrame(search_test_y)\n",
    "df.insert(1,'y_predict',y_predict)\n",
    "df.rename(columns={0:'y_test'}, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 동작구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>culture</th>\n",
       "      <th>build1</th>\n",
       "      <th>build2</th>\n",
       "      <th>build3</th>\n",
       "      <th>build4</th>\n",
       "      <th>build5</th>\n",
       "      <th>build6</th>\n",
       "      <th>build7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.023121</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.075145</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.011561</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.283237</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.375723</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.115607</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     culture    build1    build2  build3  build4  build5    build6  build7\n",
       "0        0.0  0.000000  0.000000     0.0     0.0   0.125  0.023121    0.00\n",
       "1        0.0  0.214286  0.000000     0.0     1.0   0.125  0.075145    0.25\n",
       "2        0.0  0.000000  0.000000     0.0     0.0   0.000  0.000000    0.00\n",
       "3        0.0  0.000000  0.000000     0.0     0.0   0.000  0.000000    0.00\n",
       "4        0.0  0.142857  0.000000     0.0     0.0   0.000  0.011561    0.25\n",
       "..       ...       ...       ...     ...     ...     ...       ...     ...\n",
       "131      0.0  0.500000  0.000000     0.0     0.0   0.250  0.283237    0.00\n",
       "132      0.0  0.142857  0.045455     0.0     0.0   0.000  0.375723    0.00\n",
       "133      0.0  0.142857  0.000000     0.0     0.0   0.000  0.115607    0.25\n",
       "134      0.0  0.000000  0.000000     0.0     0.0   0.000  0.000000    0.00\n",
       "135      0.0  0.000000  0.000000     0.0     0.0   0.000  0.000000    0.00\n",
       "\n",
       "[136 rows x 8 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dong_pred = pd.read_csv(\"dongjak_input.csv\")\n",
    "# dong_pred = df.iloc[:,1:]\n",
    "dong_pred = dong_pred[['culture', 'build1', 'build2', 'build3', 'build4', 'build5', 'build6','build7']]\n",
    "dong_pred\n",
    "\n",
    "pred = dong_pred.values\n",
    "pred = MinMaxScaler().fit_transform(pred)             #동작구 데이터 MinMax 전처리\n",
    "\n",
    "pred_po = pd.DataFrame(pred,columns=['culture', 'build1', 'build2', 'build3', 'build4', 'build5', 'build6','build7'])\n",
    "pred_po   #전처리 된 데이터 보려고 만든 줄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(pred)    #동작구 데이터 적용\n",
    "p = np.round(y_predict, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>culture</th>\n",
       "      <th>build1</th>\n",
       "      <th>build2</th>\n",
       "      <th>build3</th>\n",
       "      <th>build4</th>\n",
       "      <th>build5</th>\n",
       "      <th>build6</th>\n",
       "      <th>build7</th>\n",
       "      <th>result</th>\n",
       "      <th>result_round</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5.648117e-17</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>8.930811e-01</td>\n",
       "      <td>0.893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.634326e-16</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.634326e-16</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.995834e-18</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>2.117408e-19</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>3.417874e-16</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1.193614e-17</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.634326e-16</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.634326e-16</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     culture  build1  build2  build3  build4  build5  build6  build7  \\\n",
       "0          0       0       0       0       0       1       4       0   \n",
       "1          0       3       0       0      16       1      13       1   \n",
       "2          0       0       0       0       0       0       0       0   \n",
       "3          0       0       0       0       0       0       0       0   \n",
       "4          0       2       0       0       0       0       2       1   \n",
       "..       ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "131        0       7       0       0       0       2      49       0   \n",
       "132        0       2       1       0       0       0      65       0   \n",
       "133        0       2       0       0       0       0      20       1   \n",
       "134        0       0       0       0       0       0       0       0   \n",
       "135        0       0       0       0       0       0       0       0   \n",
       "\n",
       "           result  result_round  \n",
       "0    5.648117e-17         0.000  \n",
       "1    8.930811e-01         0.893  \n",
       "2    2.634326e-16         0.000  \n",
       "3    2.634326e-16         0.000  \n",
       "4    3.995834e-18         0.000  \n",
       "..            ...           ...  \n",
       "131  2.117408e-19         0.000  \n",
       "132  3.417874e-16         0.000  \n",
       "133  1.193614e-17         0.000  \n",
       "134  2.634326e-16         0.000  \n",
       "135  2.634326e-16         0.000  \n",
       "\n",
       "[136 rows x 10 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dong_pred['result'] = y_predict\n",
    "dong_pred['result_round'] = p\n",
    "dong_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>charger</th>\n",
       "      <th>destination</th>\n",
       "      <th>population</th>\n",
       "      <th>consumer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>453</td>\n",
       "      <td>1240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>453</td>\n",
       "      <td>1240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>453</td>\n",
       "      <td>1240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>453</td>\n",
       "      <td>1240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>453</td>\n",
       "      <td>1240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>416</td>\n",
       "      <td>2139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>416</td>\n",
       "      <td>2139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>416</td>\n",
       "      <td>2139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>475</td>\n",
       "      <td>2053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>475</td>\n",
       "      <td>2053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     charger  destination  population  consumer\n",
       "0          0          232         453      1240\n",
       "1          0          232         453      1240\n",
       "2          0          232         453      1240\n",
       "3          0          232         453      1240\n",
       "4          0          232         453      1240\n",
       "..       ...          ...         ...       ...\n",
       "131        1            0         416      2139\n",
       "132        0            0         416      2139\n",
       "133        2            0         416      2139\n",
       "134        0            0         475      2053\n",
       "135        0            0         475      2053\n",
       "\n",
       "[136 rows x 4 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 추가할 데이터\n",
    "dong_pred2 = pd.read_csv(\"dongjak_input.csv\")\n",
    "plus = dong_pred2[['charger','destination','population','consumer']]\n",
    "plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-34-d48fe6fd0154>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dong_pred['result'][i]=0\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3437: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>culture</th>\n",
       "      <th>build1</th>\n",
       "      <th>build2</th>\n",
       "      <th>build3</th>\n",
       "      <th>build4</th>\n",
       "      <th>build5</th>\n",
       "      <th>build6</th>\n",
       "      <th>build7</th>\n",
       "      <th>charger</th>\n",
       "      <th>destination</th>\n",
       "      <th>population</th>\n",
       "      <th>consumer</th>\n",
       "      <th>result_round</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>453</td>\n",
       "      <td>1240</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.648117e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>453</td>\n",
       "      <td>1240</td>\n",
       "      <td>0.893</td>\n",
       "      <td>8.930811e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>453</td>\n",
       "      <td>1240</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.634326e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>453</td>\n",
       "      <td>1240</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.634326e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>453</td>\n",
       "      <td>1240</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.995834e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>416</td>\n",
       "      <td>2139</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>416</td>\n",
       "      <td>2139</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.417874e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>416</td>\n",
       "      <td>2139</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>475</td>\n",
       "      <td>2053</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.634326e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>475</td>\n",
       "      <td>2053</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.634326e-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     culture  build1  build2  build3  build4  build5  build6  build7  charger  \\\n",
       "0          0       0       0       0       0       1       4       0        0   \n",
       "1          0       3       0       0      16       1      13       1        0   \n",
       "2          0       0       0       0       0       0       0       0        0   \n",
       "3          0       0       0       0       0       0       0       0        0   \n",
       "4          0       2       0       0       0       0       2       1        0   \n",
       "..       ...     ...     ...     ...     ...     ...     ...     ...      ...   \n",
       "131        0       7       0       0       0       2      49       0        1   \n",
       "132        0       2       1       0       0       0      65       0        0   \n",
       "133        0       2       0       0       0       0      20       1        2   \n",
       "134        0       0       0       0       0       0       0       0        0   \n",
       "135        0       0       0       0       0       0       0       0        0   \n",
       "\n",
       "     destination  population  consumer  result_round        result  \n",
       "0            232         453      1240         0.000  5.648117e-17  \n",
       "1            232         453      1240         0.893  8.930811e-01  \n",
       "2            232         453      1240         0.000  2.634326e-16  \n",
       "3            232         453      1240         0.000  2.634326e-16  \n",
       "4            232         453      1240         0.000  3.995834e-18  \n",
       "..           ...         ...       ...           ...           ...  \n",
       "131            0         416      2139         0.000  0.000000e+00  \n",
       "132            0         416      2139         0.000  3.417874e-16  \n",
       "133            0         416      2139         0.000  0.000000e+00  \n",
       "134            0         475      2053         0.000  2.634326e-16  \n",
       "135            0         475      2053         0.000  2.634326e-16  \n",
       "\n",
       "[136 rows x 14 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dong_pred['charger'] = plus['charger']\n",
    "dong_pred['destination'] = plus['destination']\n",
    "dong_pred['population'] = plus['population']\n",
    "dong_pred['consumer'] = plus['consumer']\n",
    "dong_pred = dong_pred[['culture', 'build1', 'build2', 'build3', 'build4', 'build5', 'build6', 'build7', \n",
    "                       'charger', 'destination', 'population', 'consumer', 'result_round', 'result']]\n",
    "\n",
    "for i in range(len(dong_pred)):\n",
    "    if dong_pred['charger'][i]!=0:\n",
    "        dong_pred['result'][i]=0\n",
    "\n",
    "dong_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dong_pred.to_csv('dongjak_result.csv', encoding='euc-kr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 동대문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-36-3d75a193bd55>:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dong_pred['result'][i]=0\n"
     ]
    }
   ],
   "source": [
    "dong_pred = pd.read_csv(\"dongdaemun_input.csv\")\n",
    "# dong_pred = df.iloc[:,1:]\n",
    "dong_pred = dong_pred[['culture', 'build1', 'build2', 'build3', 'build4', 'build5', 'build6','build7']]\n",
    "dong_pred\n",
    "\n",
    "pred = dong_pred.values\n",
    "pred = MinMaxScaler().fit_transform(pred)\n",
    "\n",
    "pred_po = pd.DataFrame(pred,columns=['culture', 'build1', 'build2', 'build3', 'build4', 'build5', 'build6','build7'])\n",
    "pred_po\n",
    "\n",
    "y_predict = model.predict(pred)\n",
    "p = np.round(y_predict, 0)\n",
    "\n",
    "dong_pred['result'] = y_predict\n",
    "dong_pred['result_round'] = p\n",
    "dong_pred\n",
    "\n",
    "# 추가할 데이터\n",
    "dong_pred2 = pd.read_csv(\"dongdaemun_input.csv\")\n",
    "plus = dong_pred2[['charger','destination','population','consumer']]\n",
    "plus\n",
    "\n",
    "dong_pred['charger'] = plus['charger']\n",
    "dong_pred['destination'] = plus['destination']\n",
    "dong_pred['population'] = plus['population']\n",
    "dong_pred['consumer'] = plus['consumer']\n",
    "dong_pred = dong_pred[['culture', 'build1', 'build2', 'build3', 'build4', 'build5', 'build6', 'build7', \n",
    "                       'charger', 'destination', 'population', 'consumer', 'result_round', 'result']]\n",
    "\n",
    "for i in range(len(dong_pred)):\n",
    "    if dong_pred['charger'][i]!=0:\n",
    "        dong_pred['result'][i]=0\n",
    "\n",
    "dong_pred.to_csv('dongdaemun_result.csv', encoding='euc-kr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 금천구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-37-c47f842149e5>:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dong_pred['result'][i]=0\n"
     ]
    }
   ],
   "source": [
    "dong_pred = pd.read_csv(\"guemchon_input.csv\")\n",
    "# dong_pred = df.iloc[:,1:]\n",
    "dong_pred = dong_pred[['culture', 'build1', 'build2', 'build3', 'build4', 'build5', 'build6','build7']]\n",
    "dong_pred\n",
    "\n",
    "pred = dong_pred.values\n",
    "pred = MinMaxScaler().fit_transform(pred)\n",
    "\n",
    "pred_po = pd.DataFrame(pred,columns=['culture', 'build1', 'build2', 'build3', 'build4', 'build5', 'build6','build7'])\n",
    "pred_po\n",
    "\n",
    "y_predict = model.predict(pred)\n",
    "p = np.round(y_predict, 0)\n",
    "\n",
    "dong_pred['result'] = y_predict\n",
    "dong_pred['result_round'] = p\n",
    "dong_pred\n",
    "\n",
    "# 추가할 데이터\n",
    "dong_pred2 = pd.read_csv(\"guemchon_input.csv\")\n",
    "plus = dong_pred2[['charger','destination','population','consumer']]\n",
    "plus\n",
    "\n",
    "dong_pred['charger'] = plus['charger']\n",
    "dong_pred['destination'] = plus['destination']\n",
    "dong_pred['population'] = plus['population']\n",
    "dong_pred['consumer'] = plus['consumer']\n",
    "dong_pred = dong_pred[['culture', 'build1', 'build2', 'build3', 'build4', 'build5', 'build6', 'build7', \n",
    "                       'charger', 'destination', 'population', 'consumer', 'result_round', 'result']]\n",
    "for i in range(len(dong_pred)):\n",
    "    if dong_pred['charger'][i]!=0:\n",
    "        dong_pred['result'][i]=0\n",
    "\n",
    "dong_pred.to_csv('guemchon_result.csv', encoding='euc-kr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 광진구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-38-d67141de796e>:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dong_pred['result'][i]=0\n"
     ]
    }
   ],
   "source": [
    "dong_pred = pd.read_csv(\"gwangjin_input.csv\")\n",
    "# dong_pred = df.iloc[:,1:]\n",
    "dong_pred = dong_pred[['culture', 'build1', 'build2', 'build3', 'build4', 'build5', 'build6','build7']]\n",
    "dong_pred\n",
    "\n",
    "pred = dong_pred.values\n",
    "pred = MinMaxScaler().fit_transform(pred)\n",
    "\n",
    "pred_po = pd.DataFrame(pred,columns=['culture', 'build1', 'build2', 'build3', 'build4', 'build5', 'build6','build7'])\n",
    "pred_po\n",
    "\n",
    "y_predict = model.predict(pred)\n",
    "p = np.round(y_predict, 0)\n",
    "\n",
    "dong_pred['result'] = y_predict\n",
    "dong_pred['result_round'] = p\n",
    "dong_pred\n",
    "\n",
    "# 추가할 데이터\n",
    "dong_pred2 = pd.read_csv(\"gwangjin_input.csv\")\n",
    "plus = dong_pred2[['charger','destination','population','consumer']]\n",
    "plus\n",
    "\n",
    "dong_pred['charger'] = plus['charger']\n",
    "dong_pred['destination'] = plus['destination']\n",
    "dong_pred['population'] = plus['population']\n",
    "dong_pred['consumer'] = plus['consumer']\n",
    "dong_pred = dong_pred[['culture', 'build1', 'build2', 'build3', 'build4', 'build5', 'build6', 'build7', \n",
    "                       'charger', 'destination', 'population', 'consumer', 'result_round', 'result']]\n",
    "\n",
    "for i in range(len(dong_pred)):\n",
    "    if dong_pred['charger'][i]!=0:\n",
    "        dong_pred['result'][i]=0\n",
    "\n",
    "dong_pred.to_csv('gwangjin_result.csv', encoding='euc-kr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 중구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-39-def148b8151f>:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dong_pred['result'][i]=0\n"
     ]
    }
   ],
   "source": [
    "dong_pred = pd.read_csv(\"jung_input.csv\")\n",
    "# dong_pred = df.iloc[:,1:]\n",
    "dong_pred = dong_pred[['culture', 'build1', 'build2', 'build3', 'build4', 'build5', 'build6','build7']]\n",
    "dong_pred\n",
    "\n",
    "pred = dong_pred.values\n",
    "pred = MinMaxScaler().fit_transform(pred)\n",
    "\n",
    "pred_po = pd.DataFrame(pred,columns=['culture', 'build1', 'build2', 'build3', 'build4', 'build5', 'build6','build7'])\n",
    "pred_po\n",
    "\n",
    "y_predict = model.predict(pred)\n",
    "p = np.round(y_predict, 0)\n",
    "\n",
    "dong_pred['result'] = y_predict\n",
    "dong_pred['result_round'] = p\n",
    "dong_pred\n",
    "\n",
    "# 추가할 데이터\n",
    "dong_pred2 = pd.read_csv(\"jung_input.csv\")\n",
    "plus = dong_pred2[['charger','destination','population','consumer']]\n",
    "plus\n",
    "\n",
    "dong_pred['charger'] = plus['charger']\n",
    "dong_pred['destination'] = plus['destination']\n",
    "dong_pred['population'] = plus['population']\n",
    "dong_pred['consumer'] = plus['consumer']\n",
    "dong_pred = dong_pred[['culture', 'build1', 'build2', 'build3', 'build4', 'build5', 'build6', 'build7', \n",
    "                       'charger', 'destination', 'population', 'consumer', 'result_round', 'result']]\n",
    "\n",
    "for i in range(len(dong_pred)):\n",
    "    if dong_pred['charger'][i]!=0:\n",
    "        dong_pred['result'][i]=0\n",
    "        \n",
    "\n",
    "dong_pred.to_csv('jung_result.csv', encoding='euc-kr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 성동구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-40-6ec2d2be6204>:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dong_pred['result'][i]=0\n"
     ]
    }
   ],
   "source": [
    "dong_pred = pd.read_csv(\"sungdong_input.csv\")\n",
    "# dong_pred = df.iloc[:,1:]\n",
    "dong_pred = dong_pred[['culture', 'build1', 'build2', 'build3', 'build4', 'build5', 'build6','build7']]\n",
    "dong_pred\n",
    "\n",
    "pred = dong_pred.values\n",
    "pred = MinMaxScaler().fit_transform(pred)\n",
    "\n",
    "pred_po = pd.DataFrame(pred,columns=['culture', 'build1', 'build2', 'build3', 'build4', 'build5', 'build6','build7'])\n",
    "pred_po\n",
    "\n",
    "y_predict = model.predict(pred)\n",
    "p = np.round(y_predict, 0)\n",
    "\n",
    "dong_pred['result'] = y_predict\n",
    "dong_pred['result_round'] = p\n",
    "dong_pred\n",
    "\n",
    "# 추가할 데이터\n",
    "dong_pred2 = pd.read_csv(\"sungdong_input.csv\")\n",
    "plus = dong_pred2[['charger','destination','population','consumer']]\n",
    "plus\n",
    "\n",
    "dong_pred['charger'] = plus['charger']\n",
    "dong_pred['destination'] = plus['destination']\n",
    "dong_pred['population'] = plus['population']\n",
    "dong_pred['consumer'] = plus['consumer']\n",
    "dong_pred = dong_pred[['culture', 'build1', 'build2', 'build3', 'build4', 'build5', 'build6', 'build7', \n",
    "                       'charger', 'destination', 'population', 'consumer', 'result_round', 'result']]\n",
    "\n",
    "for i in range(len(dong_pred)):\n",
    "    if dong_pred['charger'][i]!=0:\n",
    "        dong_pred['result'][i]=0\n",
    "\n",
    "dong_pred.to_csv('sungdong_result.csv', encoding='euc-kr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
