{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6mr3K2gmITHc"
   },
   "source": [
    "# 함수형 API\n",
    "- DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "uzVrpwJkK1Tf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "import keras\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "# import seaborn as sns\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    "from sklearn.metrics import mean_squared_error, explained_variance_score\n",
    "from keras.callbacks import EarlyStopping\n",
    "from matplotlib import font_manager, rc\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import keras\n",
    "import sklearn\n",
    "\n",
    "# 다변량\n",
    "def split_mult_data(data, timestep, lag):\n",
    "    x, y = [], []\n",
    "    for i in range(len(data)):\n",
    "        end_ix = i + timestep\n",
    "        out_end_ix = end_ix + lag\n",
    "        if out_end_ix > len(data):\n",
    "            break;\n",
    "        seq_x, seq_y = data[i:end_ix, :], data[end_ix:out_end_ix, 0]\n",
    "        x.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(x), array(y)\n",
    "\n",
    "# 단일\n",
    "def split_data(data, timestep):\n",
    "    x, y = [], []\n",
    "    for i in range(len(data)):\n",
    "        end_ix = i + timestep\n",
    "        if end_ix > len(data)-1:\n",
    "            break\n",
    "        seq_x, seq_y = data[i:end_ix], data[end_ix]\n",
    "        x.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(x), array(y)\n",
    "\n",
    "# 데이터 분할 함수 : 6.2.2\n",
    "def split(data_x, data_y):\n",
    "    train_size = int(len(data_x)*0.6)\n",
    "    val_size = int(len(data_x)*0.8)\n",
    "    \n",
    "    data_train_x = data_x[:train_size]\n",
    "    data_val_x = data_x[train_size:val_size]\n",
    "    data_test_x = data_x[val_size:]\n",
    "    \n",
    "    data_train_y = data_y[:train_size]\n",
    "    data_val_y = data_y[train_size:val_size]\n",
    "    data_test_y = data_y[val_size:] \n",
    "    \n",
    "    return data_train_x, data_val_x, data_test_x, data_train_y, data_val_y, data_test_y\n",
    "\n",
    "# 분할 데이터 정규화\n",
    "def normalization(data_train, data_val, data_test):\n",
    "    scaler = MinMaxScaler() #StandardScaler\n",
    "    scaler.fit(data_train)\n",
    "    n_data_train = scaler.transform(data_train)\n",
    "    n_data_val = scaler.transform(data_val)\n",
    "    n_data_test = scaler.transform(data_test)\n",
    "    return n_data_train, n_data_val, n_data_test\n",
    "\n",
    "# 전체 데이터 정규화\n",
    "def normalization_all(data):\n",
    "    scaler = MinMaxScaler() #StandardScaler\n",
    "    scaler.fit(data)\n",
    "    n_data = scaler.transform(data)\n",
    "    return n_data\n",
    "\n",
    "# minmax정규화\n",
    "def minmax(x):\n",
    "    n_max = np.max(x)\n",
    "    n_min = np.min(x)\n",
    "    sc = (x - n_min) / (n_max - n_min)\n",
    "    return sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9JHZi56eewSr"
   },
   "source": [
    "# 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "id": "9sorSai6ekMG",
    "outputId": "c30f7e09-ae3d-4d61-d7f6-ad70bc3f9e81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE 적용 후 학습용 피처/레이블 데이터 세트:  (998, 8) (998,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>culture</th>\n",
       "      <th>build1</th>\n",
       "      <th>build2</th>\n",
       "      <th>build3</th>\n",
       "      <th>build4</th>\n",
       "      <th>build5</th>\n",
       "      <th>build6</th>\n",
       "      <th>build7</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.036496</td>\n",
       "      <td>0.544444</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.091954</td>\n",
       "      <td>0.181102</td>\n",
       "      <td>0.584764</td>\n",
       "      <td>0.036101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>0.014599</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.409449</td>\n",
       "      <td>0.172031</td>\n",
       "      <td>0.025271</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>0.534527</td>\n",
       "      <td>0.428417</td>\n",
       "      <td>0.055438</td>\n",
       "      <td>0.461211</td>\n",
       "      <td>0.216451</td>\n",
       "      <td>0.353424</td>\n",
       "      <td>0.821432</td>\n",
       "      <td>0.347965</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>0.990837</td>\n",
       "      <td>0.550906</td>\n",
       "      <td>0.075194</td>\n",
       "      <td>0.273049</td>\n",
       "      <td>0.814748</td>\n",
       "      <td>0.149509</td>\n",
       "      <td>0.412560</td>\n",
       "      <td>0.589414</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0.014599</td>\n",
       "      <td>0.127778</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.007874</td>\n",
       "      <td>0.014664</td>\n",
       "      <td>0.010830</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>0.029197</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.390476</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>0.102362</td>\n",
       "      <td>0.386266</td>\n",
       "      <td>0.039711</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>0.367945</td>\n",
       "      <td>0.277951</td>\n",
       "      <td>0.065333</td>\n",
       "      <td>0.412596</td>\n",
       "      <td>0.163335</td>\n",
       "      <td>0.179448</td>\n",
       "      <td>0.757037</td>\n",
       "      <td>0.156892</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.051095</td>\n",
       "      <td>0.427778</td>\n",
       "      <td>0.104762</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.047244</td>\n",
       "      <td>0.062947</td>\n",
       "      <td>0.025271</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>0.816277</td>\n",
       "      <td>0.543844</td>\n",
       "      <td>0.073268</td>\n",
       "      <td>0.048402</td>\n",
       "      <td>0.968131</td>\n",
       "      <td>0.302567</td>\n",
       "      <td>0.256501</td>\n",
       "      <td>0.485460</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>0.430657</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.409449</td>\n",
       "      <td>0.888770</td>\n",
       "      <td>0.227437</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>998 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      culture    build1    build2    build3    build4    build5    build6  \\\n",
       "67   0.036496  0.544444  0.133333  0.148148  0.091954  0.181102  0.584764   \n",
       "230  0.014599  0.366667  0.266667  0.148148  0.000000  0.409449  0.172031   \n",
       "881  0.534527  0.428417  0.055438  0.461211  0.216451  0.353424  0.821432   \n",
       "692  0.990837  0.550906  0.075194  0.273049  0.814748  0.149509  0.412560   \n",
       "182  0.014599  0.127778  0.028571  0.000000  0.011494  0.007874  0.014664   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "389  0.029197  0.566667  0.390476  0.000000  0.022989  0.102362  0.386266   \n",
       "878  0.367945  0.277951  0.065333  0.412596  0.163335  0.179448  0.757037   \n",
       "128  0.051095  0.427778  0.104762  0.296296  0.068966  0.047244  0.062947   \n",
       "880  0.816277  0.543844  0.073268  0.048402  0.968131  0.302567  0.256501   \n",
       "509  0.430657  0.388889  0.047619  0.481481  0.172414  0.409449  0.888770   \n",
       "\n",
       "       build7  label  \n",
       "67   0.036101      0  \n",
       "230  0.025271      0  \n",
       "881  0.347965      1  \n",
       "692  0.589414      1  \n",
       "182  0.010830      0  \n",
       "..        ...    ...  \n",
       "389  0.039711      0  \n",
       "878  0.156892      1  \n",
       "128  0.025271      0  \n",
       "880  0.485460      1  \n",
       "509  0.227437      1  \n",
       "\n",
       "[998 rows x 9 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 코로나 데이터\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\user\\\\Desktop\\\\GBIG_PROJECT\\\\분석\\\\군집화_결과.csv\",  header=0, squeeze=True)\n",
    "X = df.iloc[:, 1:-1]\n",
    "Y = df.iloc[:, -1]\n",
    "\n",
    "smote = SMOTE(random_state=0)\n",
    "X, Y = smote.fit_resample(X.values, Y.values)\n",
    "print('SMOTE 적용 후 학습용 피처/레이블 데이터 세트: ', X.shape, Y.shape)\n",
    "\n",
    "data = pd.DataFrame(X, columns=['culture', 'build1', 'build2', 'build3', 'build4', 'build5', 'build6','build7'])\n",
    "data['label'] = Y\n",
    "\n",
    "df_shuffled=sklearn.utils.shuffle(data)\n",
    "X = df_shuffled.iloc[:, :-1]\n",
    "Y = df_shuffled.iloc[:, -1]\n",
    "\n",
    "df_shuffled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k1mMJ8kTc4dz"
   },
   "source": [
    "# 6:2:2 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "598 200 200 598 200 200 (598, 8)\n"
     ]
    }
   ],
   "source": [
    "search_train_x, search_val_x, search_test_x, search_train_y, search_val_y, search_test_y = split(X, Y)\n",
    "print(len(search_train_x), len(search_val_x), len(search_test_x), len(search_train_y), len(search_val_x), len(search_test_y), search_train_x.shape)\n",
    "#-----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M2yEK6P-djmy"
   },
   "source": [
    "# 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ptn6U-s2Yz52",
    "outputId": "34a1a00f-61ce-4a56-e036-7448dfad879c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "60/60 [==============================] - 0s 2ms/step - loss: 0.6359 - accuracy: 0.5234 - val_loss: 0.5895 - val_accuracy: 0.5650\n",
      "Epoch 2/1000\n",
      "60/60 [==============================] - 0s 781us/step - loss: 0.5483 - accuracy: 0.7241 - val_loss: 0.4982 - val_accuracy: 0.8200\n",
      "Epoch 3/1000\n",
      "60/60 [==============================] - 0s 747us/step - loss: 0.4525 - accuracy: 0.9047 - val_loss: 0.3976 - val_accuracy: 0.9300\n",
      "Epoch 4/1000\n",
      "60/60 [==============================] - 0s 764us/step - loss: 0.3553 - accuracy: 0.9666 - val_loss: 0.3054 - val_accuracy: 0.9650\n",
      "Epoch 5/1000\n",
      "60/60 [==============================] - 0s 764us/step - loss: 0.2680 - accuracy: 0.9866 - val_loss: 0.2255 - val_accuracy: 0.9700\n",
      "Epoch 6/1000\n",
      "60/60 [==============================] - 0s 747us/step - loss: 0.1928 - accuracy: 0.9967 - val_loss: 0.1590 - val_accuracy: 0.9850\n",
      "Epoch 7/1000\n",
      "60/60 [==============================] - 0s 708us/step - loss: 0.1333 - accuracy: 0.9983 - val_loss: 0.1087 - val_accuracy: 0.9850\n",
      "Epoch 8/1000\n",
      "60/60 [==============================] - 0s 731us/step - loss: 0.0880 - accuracy: 0.9983 - val_loss: 0.0730 - val_accuracy: 0.9900\n",
      "Epoch 9/1000\n",
      "60/60 [==============================] - 0s 768us/step - loss: 0.0571 - accuracy: 0.9983 - val_loss: 0.0528 - val_accuracy: 0.9850\n",
      "Epoch 10/1000\n",
      "60/60 [==============================] - 0s 697us/step - loss: 0.0375 - accuracy: 0.9983 - val_loss: 0.0366 - val_accuracy: 1.0000\n",
      "Epoch 11/1000\n",
      "60/60 [==============================] - 0s 714us/step - loss: 0.0251 - accuracy: 0.9983 - val_loss: 0.0276 - val_accuracy: 1.0000\n",
      "Epoch 12/1000\n",
      "60/60 [==============================] - 0s 698us/step - loss: 0.0180 - accuracy: 0.9983 - val_loss: 0.0242 - val_accuracy: 0.9900\n",
      "Epoch 13/1000\n",
      "60/60 [==============================] - 0s 723us/step - loss: 0.0134 - accuracy: 0.9983 - val_loss: 0.0203 - val_accuracy: 1.0000\n",
      "Epoch 14/1000\n",
      "60/60 [==============================] - 0s 681us/step - loss: 0.0103 - accuracy: 0.9983 - val_loss: 0.0167 - val_accuracy: 1.0000\n",
      "Epoch 15/1000\n",
      "60/60 [==============================] - 0s 764us/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0152 - val_accuracy: 1.0000\n",
      "Epoch 16/1000\n",
      "60/60 [==============================] - 0s 764us/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0179 - val_accuracy: 0.9850\n",
      "Epoch 17/1000\n",
      "60/60 [==============================] - 0s 714us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 1.0000\n",
      "Epoch 18/1000\n",
      "60/60 [==============================] - 0s 714us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 1.0000\n",
      "Epoch 19/1000\n",
      "60/60 [==============================] - 0s 760us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 1.0000\n",
      "Epoch 20/1000\n",
      "60/60 [==============================] - 0s 742us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0145 - val_accuracy: 0.9850\n",
      "Epoch 21/1000\n",
      "60/60 [==============================] - 0s 714us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 1.0000\n",
      "Epoch 22/1000\n",
      "60/60 [==============================] - 0s 714us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 1.0000\n",
      "Epoch 23/1000\n",
      "60/60 [==============================] - 0s 831us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 1.0000\n",
      "Epoch 24/1000\n",
      "60/60 [==============================] - 0s 747us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
      "Epoch 25/1000\n",
      "60/60 [==============================] - 0s 764us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
      "Epoch 26/1000\n",
      "60/60 [==============================] - 0s 714us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
      "Epoch 27/1000\n",
      "60/60 [==============================] - 0s 714us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
      "Epoch 28/1000\n",
      "60/60 [==============================] - 0s 714us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
      "Epoch 29/1000\n",
      "60/60 [==============================] - 0s 814us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
      "Epoch 30/1000\n",
      "60/60 [==============================] - 0s 731us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
      "Epoch 31/1000\n",
      "60/60 [==============================] - 0s 764us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 0.9950\n",
      "Epoch 32/1000\n",
      "60/60 [==============================] - 0s 747us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
      "Epoch 33/1000\n",
      "60/60 [==============================] - 0s 698us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 34/1000\n",
      "60/60 [==============================] - 0s 864us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 35/1000\n",
      "60/60 [==============================] - 0s 980us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 36/1000\n",
      "60/60 [==============================] - 0s 714us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 37/1000\n",
      "60/60 [==============================] - 0s 781us/step - loss: 9.5281e-04 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 38/1000\n",
      "60/60 [==============================] - 0s 764us/step - loss: 8.8308e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 39/1000\n",
      "60/60 [==============================] - 0s 739us/step - loss: 8.7219e-04 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 40/1000\n",
      "60/60 [==============================] - 0s 764us/step - loss: 9.1465e-04 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 41/1000\n",
      "60/60 [==============================] - 0s 764us/step - loss: 8.9125e-04 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 42/1000\n",
      "60/60 [==============================] - 0s 698us/step - loss: 8.0045e-04 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 43/1000\n",
      "60/60 [==============================] - 0s 698us/step - loss: 7.2623e-04 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 44/1000\n",
      "60/60 [==============================] - 0s 714us/step - loss: 5.6632e-04 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 45/1000\n",
      "60/60 [==============================] - 0s 773us/step - loss: 8.1004e-04 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 46/1000\n",
      "60/60 [==============================] - 0s 764us/step - loss: 5.9676e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 47/1000\n",
      "60/60 [==============================] - 0s 797us/step - loss: 5.2510e-04 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 48/1000\n",
      "60/60 [==============================] - 0s 747us/step - loss: 5.6082e-04 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 49/1000\n",
      "60/60 [==============================] - 0s 714us/step - loss: 4.3469e-04 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 50/1000\n",
      "60/60 [==============================] - 0s 664us/step - loss: 6.3176e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 51/1000\n",
      "60/60 [==============================] - 0s 747us/step - loss: 4.1716e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 52/1000\n",
      "60/60 [==============================] - 0s 696us/step - loss: 4.1255e-04 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 53/1000\n",
      "60/60 [==============================] - 0s 764us/step - loss: 4.3133e-04 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 54/1000\n",
      "60/60 [==============================] - 0s 681us/step - loss: 3.7160e-04 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 55/1000\n",
      "60/60 [==============================] - 0s 664us/step - loss: 7.7140e-04 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 56/1000\n",
      "60/60 [==============================] - 0s 664us/step - loss: 3.5211e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 57/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 681us/step - loss: 2.6294e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 58/1000\n",
      "60/60 [==============================] - 0s 697us/step - loss: 3.6508e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 59/1000\n",
      "60/60 [==============================] - 0s 664us/step - loss: 2.6251e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 60/1000\n",
      "60/60 [==============================] - 0s 664us/step - loss: 3.2929e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 61/1000\n",
      "60/60 [==============================] - 0s 797us/step - loss: 1.9524e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 62/1000\n",
      "60/60 [==============================] - 0s 648us/step - loss: 2.6880e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 63/1000\n",
      "60/60 [==============================] - 0s 698us/step - loss: 1.7103e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 64/1000\n",
      "60/60 [==============================] - 0s 714us/step - loss: 2.2839e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 65/1000\n",
      "60/60 [==============================] - 0s 681us/step - loss: 1.7986e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 66/1000\n",
      "60/60 [==============================] - 0s 714us/step - loss: 1.9504e-04 - accuracy: 1.0000 - val_loss: 8.4387e-04 - val_accuracy: 1.0000\n",
      "Epoch 67/1000\n",
      "60/60 [==============================] - 0s 731us/step - loss: 1.5675e-04 - accuracy: 1.0000 - val_loss: 9.6913e-04 - val_accuracy: 1.0000\n",
      "Epoch 68/1000\n",
      "60/60 [==============================] - 0s 702us/step - loss: 2.6753e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 69/1000\n",
      "60/60 [==============================] - 0s 681us/step - loss: 2.3113e-04 - accuracy: 1.0000 - val_loss: 9.7049e-04 - val_accuracy: 1.0000\n",
      "Epoch 70/1000\n",
      "60/60 [==============================] - 0s 719us/step - loss: 1.3893e-04 - accuracy: 1.0000 - val_loss: 9.0161e-04 - val_accuracy: 1.0000\n",
      "Epoch 71/1000\n",
      "60/60 [==============================] - 0s 681us/step - loss: 1.3919e-04 - accuracy: 1.0000 - val_loss: 7.1740e-04 - val_accuracy: 1.0000\n",
      "Epoch 72/1000\n",
      "60/60 [==============================] - 0s 698us/step - loss: 1.8203e-04 - accuracy: 1.0000 - val_loss: 7.5334e-04 - val_accuracy: 1.0000\n",
      "Epoch 73/1000\n",
      "60/60 [==============================] - 0s 764us/step - loss: 1.2779e-04 - accuracy: 1.0000 - val_loss: 5.5587e-04 - val_accuracy: 1.0000\n",
      "Epoch 74/1000\n",
      "60/60 [==============================] - 0s 731us/step - loss: 1.0523e-04 - accuracy: 1.0000 - val_loss: 6.8835e-04 - val_accuracy: 1.0000\n",
      "Epoch 75/1000\n",
      "60/60 [==============================] - 0s 664us/step - loss: 8.8807e-05 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 76/1000\n",
      "60/60 [==============================] - 0s 731us/step - loss: 8.5784e-05 - accuracy: 1.0000 - val_loss: 6.4241e-04 - val_accuracy: 1.0000\n",
      "Epoch 77/1000\n",
      "60/60 [==============================] - 0s 681us/step - loss: 9.2632e-05 - accuracy: 1.0000 - val_loss: 8.3173e-04 - val_accuracy: 1.0000\n",
      "Epoch 78/1000\n",
      "60/60 [==============================] - 0s 698us/step - loss: 1.5121e-04 - accuracy: 1.0000 - val_loss: 6.8468e-04 - val_accuracy: 1.0000\n",
      "Epoch 79/1000\n",
      "60/60 [==============================] - 0s 731us/step - loss: 7.7909e-05 - accuracy: 1.0000 - val_loss: 6.2284e-04 - val_accuracy: 1.0000\n",
      "Epoch 80/1000\n",
      "60/60 [==============================] - 0s 698us/step - loss: 6.9967e-05 - accuracy: 1.0000 - val_loss: 3.1062e-04 - val_accuracy: 1.0000\n",
      "Epoch 81/1000\n",
      "60/60 [==============================] - 0s 690us/step - loss: 7.2545e-05 - accuracy: 1.0000 - val_loss: 3.3631e-04 - val_accuracy: 1.0000\n",
      "Epoch 82/1000\n",
      "60/60 [==============================] - 0s 714us/step - loss: 6.7559e-05 - accuracy: 1.0000 - val_loss: 2.7774e-04 - val_accuracy: 1.0000\n",
      "Epoch 83/1000\n",
      "60/60 [==============================] - 0s 681us/step - loss: 5.8215e-05 - accuracy: 1.0000 - val_loss: 3.7981e-04 - val_accuracy: 1.0000\n",
      "Epoch 84/1000\n",
      "60/60 [==============================] - 0s 714us/step - loss: 5.2739e-05 - accuracy: 1.0000 - val_loss: 5.1953e-04 - val_accuracy: 1.0000\n",
      "Epoch 85/1000\n",
      "60/60 [==============================] - 0s 764us/step - loss: 1.3107e-04 - accuracy: 1.0000 - val_loss: 6.4060e-04 - val_accuracy: 1.0000\n",
      "Epoch 86/1000\n",
      "60/60 [==============================] - 0s 714us/step - loss: 5.4495e-05 - accuracy: 1.0000 - val_loss: 6.1360e-04 - val_accuracy: 1.0000\n",
      "Epoch 87/1000\n",
      "60/60 [==============================] - 0s 698us/step - loss: 1.0337e-04 - accuracy: 1.0000 - val_loss: 5.2211e-04 - val_accuracy: 1.0000\n",
      "Epoch 88/1000\n",
      "60/60 [==============================] - 0s 733us/step - loss: 6.0639e-05 - accuracy: 1.0000 - val_loss: 2.9751e-04 - val_accuracy: 1.0000\n",
      "Epoch 89/1000\n",
      "60/60 [==============================] - 0s 764us/step - loss: 3.2295e-05 - accuracy: 1.0000 - val_loss: 5.7815e-04 - val_accuracy: 1.0000\n",
      "Epoch 90/1000\n",
      "60/60 [==============================] - 0s 681us/step - loss: 7.9751e-05 - accuracy: 1.0000 - val_loss: 4.1592e-04 - val_accuracy: 1.0000\n",
      "Epoch 91/1000\n",
      "60/60 [==============================] - 0s 731us/step - loss: 4.3182e-05 - accuracy: 1.0000 - val_loss: 2.8185e-04 - val_accuracy: 1.0000\n",
      "Epoch 92/1000\n",
      "60/60 [==============================] - 0s 714us/step - loss: 3.7346e-05 - accuracy: 1.0000 - val_loss: 2.9223e-04 - val_accuracy: 1.0000\n",
      "Epoch 93/1000\n",
      "60/60 [==============================] - 0s 681us/step - loss: 3.8614e-05 - accuracy: 1.0000 - val_loss: 1.9929e-04 - val_accuracy: 1.0000\n",
      "Epoch 94/1000\n",
      "60/60 [==============================] - 0s 764us/step - loss: 3.2050e-05 - accuracy: 1.0000 - val_loss: 2.1406e-04 - val_accuracy: 1.0000\n",
      "Epoch 95/1000\n",
      "60/60 [==============================] - 0s 831us/step - loss: 4.1221e-05 - accuracy: 1.0000 - val_loss: 2.1230e-04 - val_accuracy: 1.0000\n",
      "Epoch 96/1000\n",
      "60/60 [==============================] - 0s 780us/step - loss: 2.3202e-05 - accuracy: 1.0000 - val_loss: 2.6287e-04 - val_accuracy: 1.0000\n",
      "Epoch 97/1000\n",
      "60/60 [==============================] - 0s 698us/step - loss: 3.2611e-05 - accuracy: 1.0000 - val_loss: 1.9533e-04 - val_accuracy: 1.0000\n",
      "Epoch 98/1000\n",
      "60/60 [==============================] - 0s 714us/step - loss: 3.0604e-05 - accuracy: 1.0000 - val_loss: 1.6142e-04 - val_accuracy: 1.0000\n",
      "Epoch 99/1000\n",
      "60/60 [==============================] - 0s 648us/step - loss: 2.2870e-05 - accuracy: 1.0000 - val_loss: 1.7678e-04 - val_accuracy: 1.0000\n",
      "Epoch 100/1000\n",
      "60/60 [==============================] - 0s 714us/step - loss: 2.2031e-05 - accuracy: 1.0000 - val_loss: 1.8295e-04 - val_accuracy: 1.0000\n",
      "Epoch 101/1000\n",
      "60/60 [==============================] - 0s 684us/step - loss: 2.5828e-05 - accuracy: 1.0000 - val_loss: 1.8416e-04 - val_accuracy: 1.0000\n",
      "Epoch 102/1000\n",
      "60/60 [==============================] - 0s 781us/step - loss: 1.6281e-05 - accuracy: 1.0000 - val_loss: 2.1269e-04 - val_accuracy: 1.0000\n",
      "Epoch 103/1000\n",
      "60/60 [==============================] - 0s 764us/step - loss: 1.7371e-05 - accuracy: 1.0000 - val_loss: 2.4563e-04 - val_accuracy: 1.0000\n",
      "Epoch 104/1000\n",
      "60/60 [==============================] - 0s 731us/step - loss: 1.9965e-05 - accuracy: 1.0000 - val_loss: 1.2434e-04 - val_accuracy: 1.0000\n",
      "Epoch 105/1000\n",
      "60/60 [==============================] - 0s 681us/step - loss: 1.3905e-05 - accuracy: 1.0000 - val_loss: 1.3970e-04 - val_accuracy: 1.0000\n",
      "Epoch 106/1000\n",
      "60/60 [==============================] - 0s 914us/step - loss: 1.2266e-05 - accuracy: 1.0000 - val_loss: 1.0997e-04 - val_accuracy: 1.0000\n",
      "Epoch 107/1000\n",
      "60/60 [==============================] - 0s 698us/step - loss: 1.5901e-05 - accuracy: 1.0000 - val_loss: 1.1263e-04 - val_accuracy: 1.0000\n",
      "Epoch 108/1000\n",
      "60/60 [==============================] - 0s 681us/step - loss: 8.5968e-06 - accuracy: 1.0000 - val_loss: 2.1364e-04 - val_accuracy: 1.0000\n",
      "Epoch 109/1000\n",
      "60/60 [==============================] - 0s 698us/step - loss: 3.0270e-05 - accuracy: 1.0000 - val_loss: 2.0597e-04 - val_accuracy: 1.0000\n",
      "Epoch 110/1000\n",
      "60/60 [==============================] - 0s 670us/step - loss: 1.1098e-05 - accuracy: 1.0000 - val_loss: 1.3801e-04 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/1000\n",
      "60/60 [==============================] - 0s 781us/step - loss: 9.1074e-06 - accuracy: 1.0000 - val_loss: 2.2023e-04 - val_accuracy: 1.0000\n",
      "Epoch 112/1000\n",
      "60/60 [==============================] - 0s 764us/step - loss: 1.1476e-05 - accuracy: 1.0000 - val_loss: 1.1239e-04 - val_accuracy: 1.0000\n",
      "Epoch 113/1000\n",
      "60/60 [==============================] - 0s 698us/step - loss: 1.0925e-05 - accuracy: 1.0000 - val_loss: 8.2228e-05 - val_accuracy: 1.0000\n",
      "Epoch 114/1000\n",
      "60/60 [==============================] - 0s 664us/step - loss: 7.0196e-06 - accuracy: 1.0000 - val_loss: 5.3253e-05 - val_accuracy: 1.0000\n",
      "Epoch 115/1000\n",
      "60/60 [==============================] - 0s 747us/step - loss: 4.3502e-06 - accuracy: 1.0000 - val_loss: 2.3019e-04 - val_accuracy: 1.0000\n",
      "Epoch 116/1000\n",
      "60/60 [==============================] - 0s 714us/step - loss: 1.5398e-05 - accuracy: 1.0000 - val_loss: 1.3493e-04 - val_accuracy: 1.0000\n",
      "Epoch 117/1000\n",
      "60/60 [==============================] - 0s 764us/step - loss: 9.5174e-06 - accuracy: 1.0000 - val_loss: 7.3691e-05 - val_accuracy: 1.0000\n",
      "Epoch 118/1000\n",
      "60/60 [==============================] - 0s 714us/step - loss: 4.7283e-06 - accuracy: 1.0000 - val_loss: 7.1844e-05 - val_accuracy: 1.0000\n",
      "Epoch 119/1000\n",
      "60/60 [==============================] - 0s 698us/step - loss: 8.3745e-06 - accuracy: 1.0000 - val_loss: 7.6511e-05 - val_accuracy: 1.0000\n",
      "Epoch 120/1000\n",
      "60/60 [==============================] - 0s 758us/step - loss: 3.7819e-06 - accuracy: 1.0000 - val_loss: 1.9932e-04 - val_accuracy: 1.0000\n",
      "Epoch 121/1000\n",
      "60/60 [==============================] - 0s 689us/step - loss: 6.8345e-06 - accuracy: 1.0000 - val_loss: 9.1037e-05 - val_accuracy: 1.0000\n",
      "Epoch 122/1000\n",
      "60/60 [==============================] - 0s 814us/step - loss: 3.7303e-06 - accuracy: 1.0000 - val_loss: 1.0584e-04 - val_accuracy: 1.0000\n",
      "Epoch 123/1000\n",
      "60/60 [==============================] - 0s 814us/step - loss: 3.0079e-06 - accuracy: 1.0000 - val_loss: 2.6708e-05 - val_accuracy: 1.0000\n",
      "Epoch 124/1000\n",
      "60/60 [==============================] - 0s 714us/step - loss: 1.6932e-06 - accuracy: 1.0000 - val_loss: 1.2254e-04 - val_accuracy: 1.0000\n",
      "Epoch 125/1000\n",
      "60/60 [==============================] - 0s 775us/step - loss: 3.5922e-06 - accuracy: 1.0000 - val_loss: 5.6768e-05 - val_accuracy: 1.0000\n",
      "Epoch 126/1000\n",
      "60/60 [==============================] - 0s 681us/step - loss: 3.8375e-06 - accuracy: 1.0000 - val_loss: 5.0948e-05 - val_accuracy: 1.0000\n",
      "Epoch 127/1000\n",
      "60/60 [==============================] - 0s 698us/step - loss: 1.5724e-06 - accuracy: 1.0000 - val_loss: 1.7984e-04 - val_accuracy: 1.0000\n",
      "Epoch 128/1000\n",
      "60/60 [==============================] - 0s 797us/step - loss: 4.1642e-06 - accuracy: 1.0000 - val_loss: 7.0083e-05 - val_accuracy: 1.0000\n",
      "Epoch 129/1000\n",
      "60/60 [==============================] - 0s 681us/step - loss: 2.2053e-06 - accuracy: 1.0000 - val_loss: 1.0412e-04 - val_accuracy: 1.0000\n",
      "Epoch 130/1000\n",
      "60/60 [==============================] - 0s 664us/step - loss: 2.1981e-06 - accuracy: 1.0000 - val_loss: 5.8018e-05 - val_accuracy: 1.0000\n",
      "Epoch 131/1000\n",
      "60/60 [==============================] - 0s 781us/step - loss: 3.6521e-06 - accuracy: 1.0000 - val_loss: 5.4546e-05 - val_accuracy: 1.0000\n",
      "Epoch 132/1000\n",
      "60/60 [==============================] - 0s 695us/step - loss: 1.5059e-06 - accuracy: 1.0000 - val_loss: 7.5635e-05 - val_accuracy: 1.0000\n",
      "Epoch 133/1000\n",
      "60/60 [==============================] - 0s 698us/step - loss: 6.6856e-06 - accuracy: 1.0000 - val_loss: 1.0849e-04 - val_accuracy: 1.0000\n",
      "Epoch 134/1000\n",
      "60/60 [==============================] - 0s 652us/step - loss: 2.0869e-06 - accuracy: 1.0000 - val_loss: 3.9572e-05 - val_accuracy: 1.0000\n",
      "Epoch 135/1000\n",
      "60/60 [==============================] - 0s 764us/step - loss: 1.1486e-06 - accuracy: 1.0000 - val_loss: 7.8182e-05 - val_accuracy: 1.0000\n",
      "Epoch 136/1000\n",
      "60/60 [==============================] - 0s 681us/step - loss: 1.1364e-06 - accuracy: 1.0000 - val_loss: 3.0216e-05 - val_accuracy: 1.0000\n",
      "Epoch 137/1000\n",
      "60/60 [==============================] - 0s 781us/step - loss: 1.6045e-06 - accuracy: 1.0000 - val_loss: 3.5829e-05 - val_accuracy: 1.0000\n",
      "Epoch 138/1000\n",
      "60/60 [==============================] - 0s 764us/step - loss: 6.9096e-07 - accuracy: 1.0000 - val_loss: 8.3698e-05 - val_accuracy: 1.0000\n",
      "Epoch 139/1000\n",
      "60/60 [==============================] - 0s 764us/step - loss: 1.0229e-06 - accuracy: 1.0000 - val_loss: 6.0330e-05 - val_accuracy: 1.0000\n",
      "Epoch 140/1000\n",
      "60/60 [==============================] - 0s 681us/step - loss: 8.0448e-07 - accuracy: 1.0000 - val_loss: 3.5727e-05 - val_accuracy: 1.0000\n",
      "Epoch 141/1000\n",
      "60/60 [==============================] - 0s 681us/step - loss: 6.7582e-07 - accuracy: 1.0000 - val_loss: 6.6741e-05 - val_accuracy: 1.0000\n",
      "Epoch 142/1000\n",
      "60/60 [==============================] - 0s 804us/step - loss: 1.3077e-06 - accuracy: 1.0000 - val_loss: 4.0627e-05 - val_accuracy: 1.0000\n",
      "Epoch 143/1000\n",
      "60/60 [==============================] - 0s 698us/step - loss: 4.9038e-07 - accuracy: 1.0000 - val_loss: 6.4588e-05 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras import layers, models\n",
    "from keras import Input\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.random.set_seed(555)\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(search_train_x.shape[1],)))\n",
    "model.add(layers.Dense(8, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "callback_list = [\n",
    "  keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', # 모델의 검증 정확도 모니터링\n",
    "    patience=20, # 1 에포크보다 더 길게 향상되지 않으면 중단\n",
    "  )\n",
    "]\n",
    "# batch_size : batch_size만큼 보고 가중치를 업데이트 주겠다\n",
    "hist = model.fit(search_train_x, search_train_y, epochs=1000, batch_size=10, \n",
    "                 callbacks=callback_list, validation_data=(search_val_x, search_val_y)) ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "1SO7Am6Vmipf",
    "outputId": "76fb430f-5f3f-4528-f58c-1939b3cc75d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model_20210124.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = hist.history['accuracy']\n",
    "val_acc = hist.history['val_accuracy']\n",
    "\n",
    "plt.plot(acc, 'bo', label='Training acc')\n",
    "plt.plot(val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 849
    },
    "id": "JtjmJJXyoPvZ",
    "outputId": "f4b1bb38-5ccb-482c-fe5c-9c1e4cd3cf9e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAmkUlEQVR4nO3deXxV9Z3/8dfnJiELa1aWABLRVkEwaGRo6YD++qsFbauOjMWl1tbRcbpMbWccsYs/+/Px+NWqnVpbW8t07Ghrax2XlhmZ2tqpYqdaQQccXFDAhbBIEghk3+7n98c5gUu8wAVycpOc9/PxuI97tnvu5wZy3/l+zznfY+6OiIjEVyLbBYiISHYpCEREYk5BICIScwoCEZGYUxCIiMRcbrYLOFJlZWU+bdq0bJchIjKkPP/88/XuXp5u3ZALgmnTprFmzZpslyEiMqSY2VsHW6euIRGRmFMQiIjEnIJARCTmhtwxgnS6urqora2lvb0926UMWQUFBUyePJm8vLxslyIiA2xYBEFtbS2jR49m2rRpmFm2yxly3J2GhgZqa2upqqrKdjkiMsCGRddQe3s7paWlCoGjZGaUlpaqRSUSU8MiCACFwDHSz08kvoZNEBxOW1cbW/dupbunO9uliIgMKrEJgvbudrY3b6cz2dnv+25sbOT73//+Ub32nHPOobGxMePtb7rpJm6//fajei8RkXRiEwS5ieC4eHey/1sEhwqCnp6eQ7525cqVjBs3rt9rEhHJlIKgHyxbtoxNmzZRXV3Nddddx5NPPslZZ53FJZdcwqxZswA4//zzOf3005k5cybLly/f99pp06ZRX1/Pm2++ycknn8xVV13FzJkzOfvss2lrazvk+65du5Z58+Yxe/ZsLrjgAnbv3g3AnXfeyYwZM5g9ezZLly4F4KmnnqK6uprq6mrmzJlDU1NTv/8cRGRoGhanj6a69tfXsnbH2nctd3eau5opyCkgL+fIzpWvnlDNHYvuOOj6W265hfXr17N2bfC+Tz75JM899xzr16/fdzrmPffcQ0lJCW1tbZxxxhlceOGFlJaWHrCf119/nZ///Of80z/9ExdddBEPP/wwl1122UHf9/LLL+e73/0uCxcu5MYbb+TrX/86d9xxB7fccgtvvPEG+fn5+7qdbr/9du666y7mz59Pc3MzBQUFR/QzEJHhKzYtgt6zYpIkB+T95s6de8A5+XfeeSennnoq8+bNY8uWLbz++uvvek1VVRXV1dUAnH766bz55psH3f+ePXtobGxk4cKFAHzyk59k1apVAMyePZtLL72Un/70p+TmBlk/f/58vvSlL3HnnXfS2Ni4b7mIyLD7NjjUX+5rd6yluKCY48YdF3kdI0eO3Df95JNP8sQTT/DMM89QVFTEmWeemfac/fz8/H3TOTk5h+0aOpjHHnuMVatWsWLFCm6++WZeeuklli1bxrnnnsvKlSuZN28eTzzxBCeddNJR7V9EhpfYtAggOE4QxTGC0aNHH7LPfc+ePRQXF1NUVMSrr77Ks88+e8zvOXbsWIqLi3n66acB+MlPfsLChQtJJpNs2bKFs846i1tvvZXGxkaam5vZtGkTs2bN4vrrr6empoZXX331mGsQkeFh2LUIDiWqICgtLWX+/PmccsopLF68mHPPPfeA9YsWLeLuu+9m9uzZvPe972XevHn98r733nsv11xzDa2trRx//PH8+Mc/pqenh8suu4w9e/bg7nzxi19k3LhxfO1rX+P3v/89OTk5zJgxg8WLF/dLDSIy9Jm7R7dzs0XAd4Ac4Efufkuabc4E7gDygHp3X3iofdbU1HjfG9O88sornHzyyYetZ+OujXR0dzCzYmaGnyBeMv05isjQY2bPu3tNunWRtQjMLAe4C/gQUAusNrMV7v5yyjbjgO8Di9z9bTOriKoeCFoELcmWKN9CRGTIifIYwVxgo7tvdvdO4AHgvD7bXAI84u5vA7j7zgjr2dc1FGUrSERkqIkyCCqBLSnzteGyVO8Bis3sSTN73swuT7cjM7vazNaY2Zq6urqjLig3kYvjJH1gTiEVERkKogyCdMNZ9v1TPBc4HTgX+DDwNTN7z7te5L7c3Wvcvaa8vPyoC4ry6mIRkaEqyrOGaoEpKfOTgW1ptql39xagxcxWAacCr/V3Me5gyRHgQRDkk3/4F4mIxECULYLVwIlmVmVmI4ClwIo+2/wK+HMzyzWzIuDPgFeiKGbXLnjj1THQU6AWgYhIisiCwN27gc8BjxN8uT/o7i+Z2TVmdk24zSvAr4EXgecITjFdH0U9+0ZUSObSleyK4i2OyKhRo45ouYhIVCK9oMzdVwIr+yy7u8/8bcBtUdYBBwaBWgQiIvvFZoiJKIPg+uuvP+B+BDfddBPf+ta3aG5u5oMf/CCnnXYas2bN4le/+lXG+3R3rrvuOk455RRmzZrFL37xCwC2b9/OggULqK6u5pRTTuHpp5+mp6eHK664Yt+23/72t/v184nI8Dbshpi49loIR4M+gDs0N4PlTiQ3zyk4gk9eXQ133HHw9UuXLuXaa6/lM5/5DAAPPvggv/71rykoKODRRx9lzJgx1NfXM2/ePD72sY9ldH/gRx55hLVr17Ju3Trq6+s544wzWLBgAT/72c/48Ic/zFe+8hV6enpobW1l7dq1bN26lfXrg161I7njmYjIsAuCg9n/3ZvA6d8WwZw5c9i5cyfbtm2jrq6O4uJipk6dSldXF1/+8pdZtWoViUSCrVu38s477zBhwoTD7vMPf/gDF198MTk5OYwfP56FCxeyevVqzjjjDD796U/T1dXF+eefT3V1NccffzybN2/m85//POeeey5nn312v34+ERnehl0QHOov93XrgPwW8st2cFJZ/w7BvGTJEh566CF27Nix765g999/P3V1dTz//PPk5eUxbdq0tMNPp3Owq58XLFjAqlWreOyxx/jEJz7Bddddx+WXX866det4/PHHueuuu3jwwQe55557+u2zicjwFptjBBAeJ/C8SA4WL126lAceeICHHnqIJUuWAMHw0xUVFeTl5fH73/+et956K+P9LViwgF/84hf09PRQV1fHqlWrmDt3Lm+99RYVFRVcddVVXHnllbzwwgvU19eTTCa58MILufnmm3nhhRf6/fOJyPA17FoEh5KbC91dOZEEwcyZM2lqaqKyspKJEycCcOmll/LRj36Umpoaqqurj+hGMBdccAHPPPMMp556KmbGrbfeyoQJE7j33nu57bbbyMvLY9SoUdx3331s3bqVT33qUySTwdAZ3/jGN/r984nI8BXpMNRROJZhqDdtgqaWLrrL1nH6xNMzOmgbJxqGWmT4OtQw1LHrGkr2BB9Z1xKIiAQUBCIiMTdsgiCTLq6cHACDZDTHCYayodZFKCL9Z1gEQUFBAQ0NDYf9MtMwE+m5Ow0NDRQUFGS7FBHJgmFx1tDkyZOpra3lcDetaWuD+nqgvQ7f3c6oERrgrVdBQQGTJ0/OdhkikgXDIgjy8vKoqqo67HbPPguLFwOX/B23fuYsrpt/XfTFiYgMcsOiayhTZWXBc077eHa17cpuMSIig0SsgqC0NHgu7JqiIBARCcUqCMaOhUQC8jsn0dDWkO1yREQGhWFxjCBTiUTQKsjpmKAWgYhIKFYtAgiCwNrKFQQiIqFYBoG3ligIRERCsQuCsjLobh6rYwQiIqHYBUFpKXQ0jaa1q5X27sxuEiMiMpzFMgja9haCw+623dkuR0Qk6yINAjNbZGYbzGyjmS1Ls/5MM9tjZmvDx41R1gNh11BnLnQVqXtIRIQITx81sxzgLuBDQC2w2sxWuPvLfTZ92t0/ElUdffVeVEZrmQ4Yi4gQbYtgLrDR3Te7eyfwAHBehO+Xkf1BUKogEBEh2iCoBLakzNeGy/p6n5mtM7P/MLOZ6XZkZleb2RozW3O4EUYPp3e8IVrLaGhV15CISJRBkO6GwH1vGPACcJy7nwp8F/hluh25+3J3r3H3mvLy8mMqqqQknGjTtQQiIhBtENQCU1LmJwPbUjdw973u3hxOrwTyzKyMCPUGQaJDxwhERCDaIFgNnGhmVWY2AlgKrEjdwMwmmJmF03PDeiLtrykuDp4LuysVBCIiRHjWkLt3m9nngMeBHOAed3/JzK4J198NLAH+xsy6gTZgqUd889z8fCgqgvzOCTS0PR/lW4mIDAmRjj4adves7LPs7pTp7wHfi7KGdEpKoLOzQi0CERFieGUxBN1DiXadPioiAjENgpIS8LZxurJYRISYBkFxMfS0jFWLQESEmAZBSQl0tozUCKQiIsQ0CIqLwxFIQa0CEYm9WAZBSQl0deRBV76CQERiL5ZB0HtRGe3FCgIRib1YBsH+8YYUBCIiMQ+CEo1AKiKxF8sgUNeQiMh+sQyC3hZBTruGmRARiWUQpI5AqquLRSTuYhkEY8eCGRR0T1SLQERiL5ZBkEjAuHGQ16GuIRGRWAYBBMcJEh1l6hoSkdiLbRAUF6PrCEREiHEQlJRAslUjkIqIxDoIOptHaQRSEYm92AZBcTF0NBcBGoFUROIttkFQUgItewsgaQoCEYm12AZBcTF40qBztIJARGIttkGQOgKpBp4TkTiLNAjMbJGZbTCzjWa27BDbnWFmPWa2JMp6Uu0beK6tRC0CEYm1yILAzHKAu4DFwAzgYjObcZDtvgk8HlUt6exrEWgEUhGJuShbBHOBje6+2d07gQeA89Js93ngYWBnhLW8S2+LIKe9QlcXi0isRRkElcCWlPnacNk+ZlYJXADcHWEdafW2CIp6KtUiEJFYizIILM0y7zN/B3C9u/ccckdmV5vZGjNbU1dX1y/F9QZBYZeCQETiLTfCfdcCU1LmJwPb+mxTAzxgZgBlwDlm1u3uv0zdyN2XA8sBampq+obJUSksDB55HRMUBCISa1EGwWrgRDOrArYCS4FLUjdw96reaTP7F+Df+4ZAlEpLwXSMQERiLrIgcPduM/scwdlAOcA97v6SmV0Trh/w4wJ9lZbCrladPioi8RZliwB3Xwms7LMsbQC4+xVR1pJOaSnU7RhHo4JARGIstlcWQxAEnc1jNAKpiMRa7IOgfa9GIBWReIt1EJSVaQRSEZFYB0FpaTgCafs4DTwnIrEV+yAAoK1ULQIRiS0FAUCrgkBE4ktBAGoRiEisKQiAnPbxurpYRGJLQQAUdU/RwWIRia1YB8HYsZCTAwUdlWoRiEhsxToIEolgOOrcjgnUtfbP8NYiIkNNrIMAgu6hRHs59a312S5FRCQrFASl4K0lCgIRiS0FQSl0N49lV9suepKHvFGaiMiwlFEQmNkXzGyMBf7ZzF4ws7OjLm4glJZCR9Mokp6ksb0x2+WIiAy4TFsEn3b3vcDZQDnwKeCWyKoaQKWl0Lq3ABwdMBaRWMo0CHpvRH8O8GN3X0f6m9MPOWVl0NWRC11FOk4gIrGUaRA8b2a/IQiCx81sNJCMrqyBkzrekIJAROIo01tVXglUA5vdvdXMSgi6h4a81PGGFAQiEkeZtgjeB2xw90Yzuwz4KrAnurIGjloEIhJ3mQbBD4BWMzsV+AfgLeC+yKoaQL1BMKJzEnUtOlgsIvGTaRB0u7sD5wHfcffvAKOjK2vg9AbBqO6p1LepRSAi8ZNpEDSZ2Q3AJ4DHzCwHyDvci8xskZltMLONZrYszfrzzOxFM1trZmvM7ANHVv6xKykJngu6KtU1JCKxlGkQfBzoILieYAdQCdx2qBeEYXEXsBiYAVxsZjP6bPY74FR3rwY+Dfwo89L7x4gRMGYM5LZPVBCISCxlFAThl//9wFgz+wjQ7u6HO0YwF9jo7pvdvRN4gKBrKXW/zWGXE8BIwMmCsjJItGngORGJp0yHmLgIeA74S+Ai4E9mtuQwL6sEtqTM14bL+u77AjN7FXiMoFUw4CoqINlcpoPFIhJLmXYNfQU4w90/6e6XE/y1/7XDvCbdlcfv+ovf3R9195OA84Gb0+7I7OrwGMKaurr+/7IePx46946jqbOJju6Oft+/iMhglmkQJNx9Z8p8QwavrQWmpMxPBrYdbGN3XwVMN7OyNOuWu3uNu9eUl5dnWHLmKiqgtXEUgO5UJiKxk2kQ/NrMHjezK8zsCoJunJWHec1q4EQzqzKzEcBSYEXqBmZ2gplZOH0aMIIgZAZURQU0NxZC0nScQERiJ6MhJtz9OjO7EJhP0OWz3N0fPcxrus3sc8DjQA5wj7u/ZGbXhOvvBi4ELjezLqAN+HjKweMBU1EByZ4EtBfrOIGIxE6mYw3h7g8DDx/Jzt19JX1aDmEA9E5/E/jmkewzChUV4URLhVoEIhI7hwwCM2si/SmdBri7j4mkqgG2LwiaxysIRCR2DhkE7j4shpE4HLUIRCTOYn/PYtgfBEVdVQoCEYkdBQHBwHNmUNAxVberFJHYyfhg8XCWk9M7zESlgkBEYkctglBFBSRaJ7CzZefhNxYRGUYUBKHx48Gby9jRvCPbpYiIDCgFQaiiAjqbimlobaCrpyvb5YiIDBgFQaiiAtoaR+G4jhOISKwoCEIVFdDWnA/dI3in+Z1slyMiMmAUBKH9F5WV6ziBiMSKgiCUenXxOy1qEYhIfCgIQqlBoBaBiMSJgiDUGwT5HVN1jEBEYkVBEOoNglFd09nRohaBiMSHgiA0ahQUFEB++xS1CEQkVjTWUMgsbBW0TdIxAhGJFbUIUgTDTOisIRGJFwVBigkToGtPCbvadtHZ05ntckREBoSCIEVlJTQ3jAXQKKQiEhsKghSTJkFzYyF0j9BxAhGJDQVBisrKcKJpos4cEpHYUBCkmDQpnGiqVItARGIj0iAws0VmtsHMNprZsjTrLzWzF8PHH83s1CjrOZz9LYJJOnNIRGIjsiAwsxzgLmAxMAO42Mxm9NnsDWChu88GbgaWR1VPJnpbBAWtJ6hFICKxEWWLYC6w0d03u3sn8ABwXuoG7v5Hd98dzj4LTI6wnsMqKYH8fChsn64WgYjERpRBUAlsSZmvDZcdzJXAf6RbYWZXm9kaM1tTVxfd3cPMglZBbstxahGISGxEGQSWZpmn3dDsLIIguD7dendf7u417l5TXl7ejyW+W2Ul0DRRQSAisRFlENQCU1LmJwPb+m5kZrOBHwHnuXtDhPVkpLISuhor2Na0Dfe0uSUiMqxEGQSrgRPNrMrMRgBLgRWpG5jZVOAR4BPu/lqEtWRs0iRo3TWO5o5mGtsbs12OiEjkIht91N27zexzwONADnCPu79kZteE6+8GbgRKge+bGUC3u9dEVVMmKiuhs20EdIxhy94tFBcWZ7McEZHIRToMtbuvBFb2WXZ3yvRfAX8VZQ1Hav9FZZN4e8/bzB4/O6v1iIhETVcW97HvorK9lby95+2s1iIiMhAUBH30tghyWqayZc+WQ28sIjIMKAj66A2CMR0n8/ZetQhEZPhTEPRRVATjxkFh2wnqGhKRWFAQpFFZCTktkxUEIhILCoI0Jk2Cnj0T2Lp3Kz3JnmyXIyISKQVBGpMnQ0tDCT3ew/bm7dkuR0QkUgqCNKqqYE/dSOgqUPeQiAx7CoI0pk8PJ3ZX6RRSERn2FARp7AuCXTpzSESGPwVBGiecEDznN81UEIjIsKcgSKOkBMaOhZHNs9myV11DIjK8KQjSMAu6h3J2n6gWgYgMewqCg5g+HTrrpygIRGTYUxAcxPTp0LyzjIbmRpo7m7NdjohIZBQEBzF9OvR058DeKbzWMChuniYiEgkFwUH0njnErulsqN+Q1VpERKKkIDiI/ReVncCGBgWBiAxfCoKDqKyE/HwY0zpHQSAiw5qC4CASiWDMoYK9M9U1JCLDmoLgEKZPh+SuabzW8Brunu1yREQioSA4hOnTYe/28bR0trC1aWu2yxERiUSkQWBmi8xsg5ltNLNladafZGbPmFmHmf19lLUcjZNOgs62PNgzRd1DIjJsRRYEZpYD3AUsBmYAF5vZjD6b7QL+Frg9qjqOxZw54cQOHTAWkeEryhbBXGCju292907gAeC81A3cfae7rwa6IqzjqM2eDYmEk/fOPF1UJiLDVpRBUAmkDt1ZGy47YmZ2tZmtMbM1dXV1/VJcJoqK4KSTjMKG96tFICLDVpRBYGmWHdWpN+6+3N1r3L2mvLz8GMs6MnPmQNfWU3SMQESGrSiDoBaYkjI/GdgW4ftFYs4caGso5Y2tzbR3t2e7HBGRfhdlEKwGTjSzKjMbASwFVkT4fpE47bRwYns1r9a/mtVaRESiEFkQuHs38DngceAV4EF3f8nMrjGzawDMbIKZ1QJfAr5qZrVmNiaqmo5GdXU4sWMOf6r9UzZLERGJRG6UO3f3lcDKPsvuTpneQdBlNGgVF0NVlbN15/t4pvaX/HXNX2e7JBGRfqUrizMwZ46Rt/MMnql9JtuliIj0OwVBBubMgZYdlby2dTv1rfXZLkdEpF8pCDIwb1448eZZPFv7bFZrERHpbwqCDCxcCCWljr20lGe2qHtIRIYXBUEG8vJgyYWGvXYef9j0QrbLERHpVwqCDH3845DsKOJPT5bSnezOdjkiIv1GQZChhQthbGkbHevOY/3O9dkuR0Sk3ygIMpSTA+f/RQ+89hEeWfvbbJcjItJvFARH4K8uHwXdhfzz/Y26daWIDBsKgiMwfz5MrNrFticu5MV3/ifb5YiI9AsFwREwgy9dOwJ2nMZtD/xXtssREekXCoIj9DdXjiK3qJlH75tM0pPZLkdE5JgpCI7QyJHwoSVv07p2Mb98bk22yxEROWYKgqPwzRumAsYX/r4FHTMWkaFOQXAUZp00ig9+6o/U/uEs/uFW3axGRIY2BcFR+tX3z6DgPU/zra9N47/+qGMFIjJ0KQiO0sj8Av7xhzvxwjo+MD/BBRfAf/93tqsSETlyCoJj8NcLL2D+//ssiTNv5rf/2clpp8Ell8DmzdmuTEQkcwqCY5CwBI9d+RNOv+Tf6Px8JRdds5Ff/hJOOgm+8AWoq9u/bWMjrFwJzc3ZqlZEJD0FwTEaWzCWxy97nFOmTOHBCSey5Ac3cMllnXzve1BZCXPnwvnnw8SJcO65MGsWPPHEu/fT1QXPPQfPPz/gH0FEYs6G2pg5NTU1vmbN4Dt/v7Wrla/+51e549k7GD9qPB+vuAlevJy1qwt54w346Efhz/8cbrwRXnsNJk2CyZMhNxdaWuD116G1NdjXX/wFLFsWtCK2bIG9e4OguPBCOP74o6vPHZ58EqZPh6lT++lDi8iQYWbPu3tN2nUKgv71xy1/5KYnb+K3m3/LiJwRLDxuIYtPWMwHpn6AUyecSk/nCH7wA1i/HmprIZkMLlI77rggKDZsgG98Y38opMrNhSuugIsuCloWL70E//qv8NZbUFgYPAoKoLgYqquDey1PnQp79sCVV8JvfgMjRsBVV8GXvxyEkYjEQ9aCwMwWAd8BcoAfufstfdZbuP4coBW4wt0PeQuwwR4EvV5850XuW3cfj73+GK/WB9ca5OfkU1VcxfHFx1M1LnieNHoS5UXlVIysoHxkOWVFZbyzPZenngq6lqZOhXHjoKkJbrsNli+Hzs797zNqVHBMor09eLS1QUNDMN3LLAiJm28Oguaee4JQ+cxnYMmSoLXR0ABvvAG7dgXdWMcdB6ecEjzv2hW8btQomDIleG1TUxAqpaXBezQ2Bsc/KishkYDubti6FSZMgPz8A382ra3B+jFjgtbQww8HraQrroATTojyX0UkvrISBGaWA7wGfAioBVYDF7v7yynbnAN8niAI/gz4jrv/2aH2O1SCIFXt3lqe2fIMq7etZtPuTWzevZnNuzezt2Nv2u2LC4opHxmEQ2lhKSNyRpCbyCU3kUuydSyNb1TR+PYUxpY3ccK81ygsZN/6vEQelsxjV20FOzdNoKl+DO0thSw4byOV09rIS+TRsHUsj/xwJk+tmEoyaQe8dyLhBywbkZ+ks+Pgh5JGjHBy86C1JXhNUZEzcVKSLW8n6Ow0cnOdE9+TpKICRo503n4rwcsvG8mkUV7utLZCS/jaRML5yEeMiRODrqy6OtixI7gXxOjRwXNPTxAkjY1QVAQf+hC8//1B2HV1BY/u7v3PBQXBa7dsgRfCPzHmzQsC6uWXg/eYOTMI05aWoPVUUhKEYX5+UEcyGTx6p4Nag0dOzv7pdI/W1iBI3aGsLKil91cu9VfPLPNH72t763EPlve+px34TyoCZC8I3gfc5O4fDudvAHD3b6Rs80PgSXf/eTi/ATjT3bcfbL9DMQjScXd2t+9mR/MO6lrq2Nmyk7rWOupa6qhr3T+/q20XXT1ddCW76E5273t09fSZT3Yd+SB4u46H+pMgtx0KGqF4M+TvgZYKaKyCd2ZD/XthTC2UvgbdhbBnKrhBfhN050PTJOgZEWyT1woN74U9U4J9lWyCxuNg5yxoK4aukTBqB0xaDSNaYNd0SPTArJ9B8Sb409/C+ouhuyCor6geRr2DeQI6R4MnIJHEctuwwka8pZxkbQ14TkYf1wr2AIa3j9m/MNENydwj+7kNBdYD5mBJLHwOHo4lkkDKukS4jgy+CzIIGbNMvlMyea/DbTPU6s3AYfbx4Yve4t++t+Dodn2IIIjyN6AS2JIyX0vwV//htqkEDggCM7sauBpg6jA50mlmlBSWUFJYAuX9s8+kJ+lJ9uwLhsMFR+bry+jqmUnSkziOux/wnPQk7lUpy2pxz8N5bzi/Idym93V5OGNxrwvnzw7289F23O9J+x4Hvtf+ZW1N/0b9m+Mh0YMlerCc7uCR6MFyeujuzKWjNZ+CMXsZPaEOd6exdiLte0cxbso28ke20bh1PHu3jSevsJ28ka10NI2kddc4kj05KV+kvu8Zwr/IkwncDU/aAc8kjWS4Lje/kxGjmsGNjqaRdLUVAsG+3Bwj/IpxC1oIbuE8wb7Yvzx12hL7v8jNPHh/N/DEAXU44bMn3lXjAeuSGZxAeJjvuUy/BoPPdbiNUrd5956PfB9pNwh+Bse8H95V4rsqzmQfGThuSjQnekYZBOk+ed+fTybb4O7LgeUQtAiOvbThKWEJEjkJ8nLyKKQw2+WIyBAR5XUEtcCUlPnJwLaj2EZERCIUZRCsBk40syozGwEsBVb02WYFcLkF5gF7DnV8QERE+l9kXUPu3m1mnwMeJzh99B53f8nMrgnX3w2sJDhjaCPB6aOfiqoeERFJL9LTJdx9JcGXfeqyu1OmHfhslDWIiMihaawhEZGYUxCIiMScgkBEJOYUBCIiMTfkRh81szrgraN8eRlQ34/lREm1RkO1RkO19r/+rvM4d087jsGQC4JjYWZrDjbWxmCjWqOhWqOhWvvfQNapriERkZhTEIiIxFzcgmB5tgs4Aqo1Gqo1Gqq1/w1YnbE6RiAiIu8WtxaBiIj0oSAQEYm52ASBmS0ysw1mttHMlmW7nlRmNsXMfm9mr5jZS2b2hXB5iZn91sxeD5+Ls10rBPejNrP/NrN/D+cHa53jzOwhM3s1/Nm+bxDX+sXw3369mf3czAoGS61mdo+Z7TSz9SnLDlqbmd0Q/p5tMLMPD4Jabwv/D7xoZo+a2bjBWmvKur83MzezsoGoNRZBYGY5wF3AYmAGcLGZzchuVQfoBv7O3U8G5gGfDetbBvzO3U8EfhfODwZfAF5JmR+sdX4H+LW7nwScSlDzoKvVzCqBvwVq3P0UgmHblzJ4av0XYFGfZWlrC//fLgVmhq/5fvj7N1D+hXfX+lvgFHefDbwG3ACDtlbMbArwIeDtlGWR1hqLIADmAhvdfbO7dwIPAOdluaZ93H27u78QTjcRfGFVEtR4b7jZvcD5WSkwhZlNBs4FfpSyeDDWOQZYAPwzgLt3unsjg7DWUC5QaGa5QBHBnfoGRa3uvgrY1WfxwWo7D3jA3Tvc/Q2Ce43MHYg6IX2t7v4bd+8OZ58luBPioKw19G3gHzjwtr2R1hqXIKgEtqTM14bLBh0zmwbMAf4EjO+9Y1v4XJHF0nrdQfCfNJmybDDWeTxQB/w47Mb6kZmNZBDW6u5bgdsJ/gLcTnCnvt8wCGtNcbDaBvvv2qeB/winB12tZvYxYKu7r+uzKtJa4xIElmbZoDtv1sxGAQ8D17r73mzX05eZfQTY6e7PZ7uWDOQCpwE/cPc5QAuDoBsonbB//TygCpgEjDSzy7Jb1VEbtL9rZvYVgm7Y+3sXpdksa7WaWRHwFeDGdKvTLOu3WuMSBLXAlJT5yQRN70HDzPIIQuB+d38kXPyOmU0M108EdmarvtB84GNm9iZB99r/MrOfMvjqhODfvNbd/xTOP0QQDIOx1v8NvOHude7eBTwCvJ/BWWuvg9U2KH/XzOyTwEeAS33/xVODrdbpBH8MrAt/xyYDL5jZBCKuNS5BsBo40cyqzGwEwUGXFVmuaR8zM4K+7Ffc/R9TVq0APhlOfxL41UDXlsrdb3D3ye4+jeBn+J/ufhmDrE4Ad98BbDGz94aLPgi8zCCslaBLaJ6ZFYX/Fz5IcJxoMNba62C1rQCWmlm+mVUBJwLPZaG+fcxsEXA98DF3b01ZNahqdff/cfcKd58W/o7VAqeF/5ejrdXdY/EAziE4Y2AT8JVs19Ontg8QNPNeBNaGj3OAUoIzMl4Pn0uyXWtKzWcC/x5OD8o6gWpgTfhz/SVQPIhr/TrwKrAe+AmQP1hqBX5OcOyii+DL6cpD1UbQvbEJ2AAsHgS1biToX+/93bp7sNbaZ/2bQNlA1KohJkREYi4uXUMiInIQCgIRkZhTEIiIxJyCQEQk5hQEIiIxpyAQGUBmdmbvqK0ig4WCQEQk5hQEImmY2WVm9pyZrTWzH4b3YGg2s2+Z2Qtm9jszKw+3rTazZ1PGuy8Ol59gZk+Y2brwNdPD3Y+y/fdJuD+8mlgkaxQEIn2Y2cnAx4H57l4N9ACXAiOBF9z9NOAp4P+EL7kPuN6D8e7/J2X5/cBd7n4qwdhB28Plc4BrCe6NcTzBGE4iWZOb7QJEBqEPAqcDq8M/1gsJBlVLAr8It/kp8IiZjQXGuftT4fJ7gX81s9FApbs/CuDu7QDh/p5z99pwfi0wDfhD5J9K5CAUBCLvZsC97n7DAQvNvtZnu0ONz3Ko7p6OlOke9HsoWaauIZF3+x2wxMwqYN/9eY8j+H1ZEm5zCfAHd98D7DazPw+XfwJ4yoP7SdSa2fnhPvLD8eZFBh39JSLSh7u/bGZfBX5jZgmC0SE/S3Bzm5lm9jywh+A4AgTDMN8dftFvBj4VLv8E8EMz+7/hPv5yAD+GSMY0+qhIhsys2d1HZbsOkf6mriERkZhTi0BEJObUIhARiTkFgYhIzCkIRERiTkEgIhJzCgIRkZj7/4+OQksfH0nxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>y_predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>1</td>\n",
       "      <td>9.999980e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>0</td>\n",
       "      <td>1.578827e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0</td>\n",
       "      <td>3.990614e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>0</td>\n",
       "      <td>1.487603e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0</td>\n",
       "      <td>2.744318e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label     y_predict\n",
       "909      1  9.999980e-01\n",
       "750      1  1.000000e+00\n",
       "358      0  1.578827e-08\n",
       "105      0  3.990614e-08\n",
       "772      1  1.000000e+00\n",
       "..     ...           ...\n",
       "389      0  1.487603e-10\n",
       "878      1  1.000000e+00\n",
       "128      0  2.744318e-08\n",
       "880      1  1.000000e+00\n",
       "509      1  1.000000e+00\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습 시각화 함수\n",
    "def learning_graph(hist):\n",
    "    fig, loss_ax = plt.subplots()\n",
    "    loss_ax.plot(hist.history['loss'],'g', label='train loss')\n",
    "    loss_ax.plot(hist.history['val_loss'],'b', label='val loss')\n",
    "    loss_ax.set_xlabel('epoch')\n",
    "    loss_ax.set_ylabel('loss')\n",
    "    loss_ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "learning_graph(hist)\n",
    "\n",
    "# 실제값, 예측값 그래프\n",
    "y_predict = model.predict(search_test_x) ####\n",
    "\n",
    "# 에러율 - Root Mean Squared Error\n",
    "# rmse = np.sqrt(mean_squared_error(y_predict, search_test_y))\n",
    "# print('RMSE: ',rmse.round(2))\n",
    "\n",
    "# r = explained_variance_score(search_test_y, y_predict)\n",
    "# print('R-Square: ',r.round(2))\n",
    "\n",
    "# fig, loss_ax = plt.subplots()\n",
    "# loss_ax.bar(search_test_y)\n",
    "# loss_ax.bar(y_predict)\n",
    "# loss_ax.legend(loc='upper left')\n",
    "# plt.show()\n",
    "\n",
    "df = pd.DataFrame(search_test_y)\n",
    "df.insert(1,'y_predict',y_predict)\n",
    "df.rename(columns={0:'y_test'}, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 동작구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>culture</th>\n",
       "      <th>build1</th>\n",
       "      <th>build2</th>\n",
       "      <th>build3</th>\n",
       "      <th>build4</th>\n",
       "      <th>build5</th>\n",
       "      <th>build6</th>\n",
       "      <th>build7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.023121</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.075145</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.011561</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.283237</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.375723</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.115607</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     culture    build1    build2  build3  build4  build5    build6  build7\n",
       "0        0.0  0.000000  0.000000     0.0     0.0   0.125  0.023121    0.00\n",
       "1        0.0  0.214286  0.000000     0.0     1.0   0.125  0.075145    0.25\n",
       "2        0.0  0.000000  0.000000     0.0     0.0   0.000  0.000000    0.00\n",
       "3        0.0  0.000000  0.000000     0.0     0.0   0.000  0.000000    0.00\n",
       "4        0.0  0.142857  0.000000     0.0     0.0   0.000  0.011561    0.25\n",
       "..       ...       ...       ...     ...     ...     ...       ...     ...\n",
       "131      0.0  0.500000  0.000000     0.0     0.0   0.250  0.283237    0.00\n",
       "132      0.0  0.142857  0.045455     0.0     0.0   0.000  0.375723    0.00\n",
       "133      0.0  0.142857  0.000000     0.0     0.0   0.000  0.115607    0.25\n",
       "134      0.0  0.000000  0.000000     0.0     0.0   0.000  0.000000    0.00\n",
       "135      0.0  0.000000  0.000000     0.0     0.0   0.000  0.000000    0.00\n",
       "\n",
       "[136 rows x 8 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dong_pred = pd.read_csv(\"C:\\\\Users\\\\user\\\\Desktop\\\\GBIG_PROJECT\\\\분석\\\\자치구\\\\dongjak_input.csv\")\n",
    "# dong_pred = df.iloc[:,1:]\n",
    "dong_pred = dong_pred[['culture', 'build1', 'build2', 'build3', 'build4', 'build5', 'build6','build7']]\n",
    "dong_pred\n",
    "\n",
    "pred = dong_pred.values\n",
    "pred = MinMaxScaler().fit_transform(pred)\n",
    "\n",
    "pred_po = pd.DataFrame(pred,columns=['culture', 'build1', 'build2', 'build3', 'build4', 'build5', 'build6','build7'])\n",
    "pred_po"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(pred)\n",
    "# p = np.round(y_predict, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>culture</th>\n",
       "      <th>build1</th>\n",
       "      <th>build2</th>\n",
       "      <th>build3</th>\n",
       "      <th>build4</th>\n",
       "      <th>build5</th>\n",
       "      <th>build6</th>\n",
       "      <th>build7</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.228142e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>9.999057e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.970920e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.970920e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.004691e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>4.839789e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>1.031191e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>2.898955e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.970920e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.970920e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     culture  build1  build2  build3  build4  build5  build6  build7  \\\n",
       "0          0       0       0       0       0       1       4       0   \n",
       "1          0       3       0       0      16       1      13       1   \n",
       "2          0       0       0       0       0       0       0       0   \n",
       "3          0       0       0       0       0       0       0       0   \n",
       "4          0       2       0       0       0       0       2       1   \n",
       "..       ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "131        0       7       0       0       0       2      49       0   \n",
       "132        0       2       1       0       0       0      65       0   \n",
       "133        0       2       0       0       0       0      20       1   \n",
       "134        0       0       0       0       0       0       0       0   \n",
       "135        0       0       0       0       0       0       0       0   \n",
       "\n",
       "           result  \n",
       "0    1.228142e-10  \n",
       "1    9.999057e-01  \n",
       "2    2.970920e-10  \n",
       "3    2.970920e-10  \n",
       "4    2.004691e-11  \n",
       "..            ...  \n",
       "131  4.839789e-13  \n",
       "132  1.031191e-10  \n",
       "133  2.898955e-11  \n",
       "134  2.970920e-10  \n",
       "135  2.970920e-10  \n",
       "\n",
       "[136 rows x 9 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dong_pred['result'] = y_predict\n",
    "dong_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "dong_pred.to_csv('C:\\\\Users\\\\user\\\\Desktop\\\\GBIG_PROJECT\\\\분석\\\\DNN.csv', encoding='euc-kr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 동대문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "dong_pred = pd.read_csv(\"C:\\\\Users\\\\user\\\\Desktop\\\\GBIG_PROJECT\\\\분석\\\\자치구\\\\dongdaemun_input.csv\")\n",
    "# dong_pred = df.iloc[:,1:]\n",
    "dong_pred = dong_pred[['culture', 'build1', 'build2', 'build3', 'build4', 'build5', 'build6','build7']]\n",
    "dong_pred\n",
    "\n",
    "pred = dong_pred.values\n",
    "pred = MinMaxScaler().fit_transform(pred)\n",
    "\n",
    "pred_po = pd.DataFrame(pred,columns=['culture', 'build1', 'build2', 'build3', 'build4', 'build5', 'build6','build7'])\n",
    "pred_po\n",
    "\n",
    "y_predict = model.predict(pred)\n",
    "# p = np.round(y_predict, 0)\n",
    "\n",
    "dong_pred['result'] = y_predict\n",
    "dong_pred\n",
    "\n",
    "dong_pred.to_csv('C:\\\\Users\\\\user\\\\Desktop\\\\GBIG_PROJECT\\\\분석\\\\DNN_dongdae.csv', encoding='euc-kr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 금천구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "dong_pred = pd.read_csv(\"C:\\\\Users\\\\user\\\\Desktop\\\\GBIG_PROJECT\\\\분석\\\\자치구\\\\guemchon_input.csv\")\n",
    "# dong_pred = df.iloc[:,1:]\n",
    "dong_pred = dong_pred[['culture', 'build1', 'build2', 'build3', 'build4', 'build5', 'build6','build7']]\n",
    "dong_pred\n",
    "\n",
    "pred = dong_pred.values\n",
    "pred = MinMaxScaler().fit_transform(pred)\n",
    "\n",
    "pred_po = pd.DataFrame(pred,columns=['culture', 'build1', 'build2', 'build3', 'build4', 'build5', 'build6','build7'])\n",
    "pred_po\n",
    "\n",
    "y_predict = model.predict(pred)\n",
    "# p = np.round(y_predict, 0)\n",
    "\n",
    "dong_pred['result'] = y_predict\n",
    "dong_pred\n",
    "\n",
    "dong_pred.to_csv('C:\\\\Users\\\\user\\\\Desktop\\\\GBIG_PROJECT\\\\분석\\\\DNN_guemchon.csv', encoding='euc-kr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 광진구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "dong_pred = pd.read_csv(\"C:\\\\Users\\\\user\\\\Desktop\\\\GBIG_PROJECT\\\\분석\\\\자치구\\\\gwangjin_input.csv\")\n",
    "# dong_pred = df.iloc[:,1:]\n",
    "dong_pred = dong_pred[['culture', 'build1', 'build2', 'build3', 'build4', 'build5', 'build6','build7']]\n",
    "dong_pred\n",
    "\n",
    "pred = dong_pred.values\n",
    "pred = MinMaxScaler().fit_transform(pred)\n",
    "\n",
    "pred_po = pd.DataFrame(pred,columns=['culture', 'build1', 'build2', 'build3', 'build4', 'build5', 'build6','build7'])\n",
    "pred_po\n",
    "\n",
    "y_predict = model.predict(pred)\n",
    "# p = np.round(y_predict, 0)\n",
    "\n",
    "dong_pred['result'] = y_predict\n",
    "dong_pred\n",
    "\n",
    "dong_pred.to_csv('C:\\\\Users\\\\user\\\\Desktop\\\\GBIG_PROJECT\\\\분석\\\\DNN_gwangjin.csv', encoding='euc-kr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# jung?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (130) does not match length of index (88)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-138-4f3668be3419>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# p = np.round(y_predict, 0)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mdong_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'result'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mdong_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\flask\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3161\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3162\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3163\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3165\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\flask\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3240\u001b[0m         \"\"\"\n\u001b[0;32m   3241\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3242\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3243\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\flask\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[1;34m(self, key, value, broadcast)\u001b[0m\n\u001b[0;32m   3897\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3898\u001b[0m             \u001b[1;31m# turn me into an ndarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3899\u001b[1;33m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msanitize_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3900\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3901\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\flask\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36msanitize_index\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    750\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    751\u001b[0m         raise ValueError(\n\u001b[1;32m--> 752\u001b[1;33m             \u001b[1;34m\"Length of values \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    753\u001b[0m             \u001b[1;34mf\"({len(data)}) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    754\u001b[0m             \u001b[1;34m\"does not match length of index \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (130) does not match length of index (88)"
     ]
    }
   ],
   "source": [
    "dong_pred = pd.read_csv(\"C:\\\\Users\\\\user\\\\Desktop\\\\GBIG_PROJECT\\\\분석\\\\자치구\\\\jung_input.csv\")\n",
    "# dong_pred = df.iloc[:,1:]\n",
    "dong_pred = dong_pred[['culture', 'build1', 'build2', 'build3', 'build4', 'build5', 'build6','build7']]\n",
    "dong_pred\n",
    "\n",
    "pred = dong_pred.values\n",
    "pred = MinMaxScaler().fit_transform(pred)\n",
    "\n",
    "pred_po = pd.DataFrame(pred,columns=['culture', 'build1', 'build2', 'build3', 'build4', 'build5', 'build6','build7'])\n",
    "pred_po\n",
    "\n",
    "y_predict = model.predict(pred)\n",
    "# p = np.round(y_predict, 0)\n",
    "\n",
    "dong_pred['result'] = y_predict\n",
    "dong_pred\n",
    "\n",
    "dong_pred.to_csv('C:\\\\Users\\\\user\\\\Desktop\\\\GBIG_PROJECT\\\\분석\\\\DNN_jung.csv', encoding='euc-kr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 성동구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "dong_pred = pd.read_csv(\"C:\\\\Users\\\\user\\\\Desktop\\\\GBIG_PROJECT\\\\분석\\\\자치구\\\\sungdong_input.csv\")\n",
    "# dong_pred = df.iloc[:,1:]\n",
    "dong_pred = dong_pred[['culture', 'build1', 'build2', 'build3', 'build4', 'build5', 'build6','build7']]\n",
    "dong_pred\n",
    "\n",
    "pred = dong_pred.values\n",
    "pred = MinMaxScaler().fit_transform(pred)\n",
    "\n",
    "pred_po = pd.DataFrame(pred,columns=['culture', 'build1', 'build2', 'build3', 'build4', 'build5', 'build6','build7'])\n",
    "pred_po\n",
    "\n",
    "y_predict = model.predict(pred)\n",
    "# p = np.round(y_predict, 0)\n",
    "\n",
    "dong_pred['result'] = y_predict\n",
    "dong_pred\n",
    "\n",
    "dong_pred.to_csv('C:\\\\Users\\\\user\\\\Desktop\\\\GBIG_PROJECT\\\\분석\\\\DNN_sungdong.csv', encoding='euc-kr')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
